{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "diffphysics.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyM+TsBq4JhiZeN7vQb/vmJO"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZsuef7jB5Yr"
      },
      "source": [
        "!apt-get install gcc-4.8 gcc-5 g++-4.8 g++-5\n",
        "!apt-get install libblas-dev liblapack-dev\n",
        "!apt-get install libopenblas-dev\n",
        "!apt-get install gfortran-4.8\n",
        "!apt-get install gfortran-5\n",
        "!apt-get install scons\n",
        "!apt-get install libpng-dev\n",
        "!apt-get install libboost-all-dev freeglut3-dev\n",
        "!apt-get install xvfb\n",
        "!apt-get install libspatialindex-dev"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTptZ_EcRVDx"
      },
      "source": [
        "!pip install torch==1.3.0 rtree trimesh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlGtkZ2EFpa3"
      },
      "source": [
        "!update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-4.8 10\n",
        "!update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-5 20\n",
        "!update-alternatives --install /usr/bin/g++ g++ /usr/bin/g++-4.8 10\n",
        "!update-alternatives --install /usr/bin/g++ g++ /usr/bin/g++-5 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhrYLFEAGkSX"
      },
      "source": [
        "!git clone https://github.com/mszarski/diffsim.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TEcm4SkIwMZ"
      },
      "source": [
        "!chmod +x diffsim/arcsim/dependencies/taucs/configure"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kb4ei9vb4tps"
      },
      "source": [
        "%cd /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tv2nSDLkCBRI"
      },
      "source": [
        "%cd diffsim\n",
        "!update-alternatives --set gcc \"/usr/bin/gcc-4.8\"\n",
        "!update-alternatives --set g++ \"/usr/bin/g++-4.8\"\n",
        "%cd arcsim/dependencies/\n",
        "!make \n",
        "%cd ../..\n",
        "!update-alternatives --set gcc \"/usr/bin/gcc-5\"\n",
        "!update-alternatives --set g++ \"/usr/bin/g++-5\"\n",
        "!make -j 8\n",
        "%cd pysim\n",
        "!ln -s ../arcsim/conf ./conf\n",
        "!ln -s ../arcsim/materials ./materials\n",
        "!ln -s ../arcsim/meshes ./meshes\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTxX1QyIVKd3"
      },
      "source": [
        "##restart runtime here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUFEtzDdErjH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aaebde35-a80c-4613-dbcc-3d8179282ffd"
      },
      "source": [
        "%cd /content/diffsim/pysim"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/diffsim/pysim\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PurB50ZUweo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4879b9ae-e50d-4cea-dd82-ace0ef7ec6d7"
      },
      "source": [
        "from google.colab import drive\n",
        "from os.path import join\n",
        "\n",
        "ROOT = '/content/drive'     # default for the drive\n",
        "PROJ = 'My Drive/draping_workspace'       # path to your project on Drive\n",
        "\n",
        "drive.mount(ROOT)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kd3sYbMBG-FB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b019df7-a82e-45af-e923-179f1b2bb64c"
      },
      "source": [
        "%%writefile conf/draping.json\n",
        "{\n",
        "    \"frame_time\": 0.125,\n",
        "    \"frame_steps\": 1,\n",
        "    \"end_time\": 10,\n",
        "    \"cloths\": [\n",
        "    {\n",
        "        \"mesh\": \"/content/drive/My Drive/draping_workspace/2d_shape_flatmesh_99pc.obj\",\n",
        "        \"transform\":{\"scale\":0.01,\"translate\":[-0.1,-0.3,0.3]},\n",
        "        \"materials\": [{\"data\": \"materials/gray-interlock.json\",\n",
        "                       \"thicken\": 2}],\n",
        "        \"remeshing\": {\n",
        "            \"refine_angle\": 0.3,\n",
        "            \"refine_compression\": 0.005,\n",
        "            \"refine_velocity\": 0.5,\n",
        "            \"size\": [10e-3, 100e-3],\n",
        "            \"aspect_min\": 0.2\n",
        "        }\n",
        "    }\n",
        "    ],\n",
        "    \"obstacles\": [\n",
        "    {\n",
        "        \"mesh\": \"/content/drive/My Drive/draping_workspace/3d_shape.obj\",\n",
        "        \"transform\":{\"scale\":0.01,\"translate\":[-0.1,-0.3,-0.5]},\n",
        "        \"velocity\": [0, 0, 0, 0, 0, 0],\n",
        "        \"movable\": 0\n",
        "    }\n",
        "    ],\n",
        "    \"disable\":[\"remeshing\", \"proximity\"],\n",
        "    \"handles\": [{\"nodes\": [302, 198, 2, 23]}],\n",
        "    \"gravity\":[0, 0, -2],\n",
        "    \"magic\": {\"repulsion_thickness\": 5e-3, \"collision_stiffness\": 1e6}\n",
        "}"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing conf/draping.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rw85Gs4RsXC"
      },
      "source": [
        "import trimesh\n",
        "import trimesh.transformations as tf\n",
        "import numpy as np\n",
        "\n",
        "curved_mesh = trimesh.load('/content/drive/My Drive/draping_workspace/3d_shape.obj',process=False)\n",
        "flat_mesh = trimesh.load('/content/drive/My Drive/draping_workspace/2d_shape_flatmesh_99pc.obj',process=False)\n",
        "scene = trimesh.Scene(base_frame='world')\n",
        "curved_mesh.apply_scale(0.01)\n",
        "flat_mesh.apply_scale(0.01)\n",
        "\n",
        "transform = tf.translation_matrix([-0.1,-0.3,0.3])\n",
        "flat_mesh.apply_transform(transform)\n",
        "f_id = scene.add_geometry(flat_mesh)\n",
        "\n",
        "transform = tf.translation_matrix([-0.1,-0.3,-0.5])\n",
        "curved_mesh.apply_transform(transform)\n",
        "c_id = scene.add_geometry(curved_mesh)\n",
        "\n",
        "handles = [302, 198, 2, 23]\n",
        "steps = 30\n",
        "\n",
        "trajectories = []\n",
        "\n",
        "for handle in handles:\n",
        "    ray_origin = flat_mesh.vertices[handle]\n",
        "    \n",
        "    ray_direction = curved_mesh.vertices[handle] - flat_mesh.vertices[handle]\n",
        "    ray_direction = ray_direction\n",
        "\n",
        "    locations, index_ray, index_tri = curved_mesh.ray.intersects_location(\n",
        "        ray_origins=np.array([ray_origin]),\n",
        "        ray_directions=np.array([ray_direction]))\n",
        "\n",
        "    location = locations[0]\n",
        "    path = np.dstack([np.linspace(ray_origin[0],location[0],steps),np.linspace(ray_origin[1],location[1],steps),np.linspace(ray_origin[2],location[2],steps)])\n",
        "\n",
        "    path = path.squeeze()\n",
        "    trajectories.append(path)\n",
        "\n",
        "trajectories = np.array(trajectories) #this is positions, not vs\n",
        "trajectories = np.diff(trajectories,axis=1) #vs\n",
        "trajectories = trajectories.transpose(1,0,2)\n",
        "trajectories = np.concatenate([trajectories,np.expand_dims(np.zeros_like(trajectories[0]),0)])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvGR5_SgfTOn"
      },
      "source": [
        "!rm -rf /content/default_out"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upkjhK1wUQ2L",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bce78597-563f-4dfa-ca0a-c65d0b8f6cc8"
      },
      "source": [
        "import torch\n",
        "import arcsim\n",
        "import gc\n",
        "import time\n",
        "import json\n",
        "#import sysx\n",
        "import gc\n",
        "import os\n",
        "#import numpy as np\n",
        "\n",
        "from datetime import datetime\n",
        "now = datetime.now()\n",
        "timestamp = datetime.now().strftime('%Y-%m-%d_%H:%M:%S')\n",
        "\n",
        "out_path = '/content/default_out'\n",
        "\n",
        "if not os.path.exists(out_path):\n",
        "  os.mkdir(out_path)\n",
        "\n",
        "with open('conf/draping.json','r') as f:\n",
        "  config = json.load(f)\n",
        "\n",
        "def save_config(config, file):\n",
        "  with open(file,'w') as f:\n",
        "    json.dump(config, f)\n",
        "\n",
        "save_config(config, out_path+'/conf.json')\n",
        "\n",
        "torch.set_num_threads(8)\n",
        "spf = config['frame_steps']\n",
        "frame_time = config['frame_time']\n",
        "scalev=1\n",
        "\n",
        "pre_steps = 10\n",
        "#steps=30\n",
        "epochs=10\n",
        "\n",
        "seed_point_index = 292\n",
        "#handles = [302, 198, 2, 23]\n",
        "boundary = [  2,   1,  68,  74,  77,  79,  81,  83,  85,  87,  89, 198,  65, \n",
        "         63,  61,  59,  57,  55,  53,  51,  49,  47,  45,  43,  41,  39,\n",
        "         37,  35,  33,  31,  29,  27,  25,  24,  23,  21,  19,  17,  15,\n",
        "         13,  11,   9,   7,   4,   3, 302,  92,  91,  95,  98,  97, 101,\n",
        "        103, 105, 107, 109, 111, 113, 115, 117, 119, 121, 123, 125, 127,\n",
        "        129, 131, 133, 139, 141,   0]\n",
        "\n",
        "def reset_sim(sim, epoch):\n",
        "  if epoch < epochs:\n",
        "    arcsim.init_physics(out_path+'/conf.json', out_path+'/out%d'%epoch,False)\n",
        "  else:\n",
        "    arcsim.init_physics(out_path+'/conf.json',out_path+'/out',False)\n",
        "\n",
        "def run_sim(steps,sim,param_v):\n",
        "\n",
        "  loss = 0.\n",
        "\n",
        "  print(\"step\")\n",
        "  for step in range(pre_steps + steps):\n",
        "    print(step)\n",
        "\n",
        "    if step > pre_steps:\n",
        "      for i in range(len(handles)):\n",
        "        sim.cloths[0].mesh.nodes[handles[i]].v += param_v[step-pre_steps,i] * spf\n",
        "        print(sim.cloths[0].mesh.nodes[handles[i]].x)\n",
        "\n",
        "    # from IPython.core.debugger import set_trace\n",
        "    # set_trace()\n",
        "\n",
        "    #print(sim.obstacles[0].curr_state_mesh.nodes[seed_point_index].x - sim.cloths[0].mesh.nodes[seed_point_index].x)\n",
        "    \n",
        "    loss_idxs = [*boundary]\n",
        "\n",
        "    if step > pre_steps:\n",
        "      for i in loss_idxs:\n",
        "        loss += torch.norm(sim.obstacles[0].curr_state_mesh.nodes[i].x - sim.cloths[0].mesh.nodes[i].x, p=1) #* (1 + ((step-pre_steps)/steps))\n",
        "\n",
        "    arcsim.sim_step()\n",
        "\n",
        "\n",
        "  v_limit = 0.5 #was 0.25\n",
        "  stiffness = 2\n",
        "  weight = 2/30 * steps * 1/7 * len(loss_idxs)\n",
        "  v_constraint = torch.sum(weight / (1.0+torch.exp(stiffness*(1.0 - (torch.abs(param_v)/v_limit)))))\n",
        "\n",
        "  avg = torch.mean(param_v,dim=1,keepdim=True)\n",
        "  reg = (torch.norm(param_v-avg, dim=2)**2).mean()\n",
        "\n",
        "  total_loss = loss + reg + v_constraint\n",
        "\n",
        "  return total_loss\n",
        "\n",
        "def do_train(cur_step,optimizer,scheduler,sim,param_v):\n",
        "  epoch = 0\n",
        "  while True:\n",
        "    reset_sim(sim, epoch)\n",
        "    st = time.time()\n",
        "    loss = run_sim(steps, sim, param_v)\n",
        "    en0 = time.time()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    loss.backward(retain_graph=True)\n",
        "\n",
        "    en1 = time.time()\n",
        "    print(\"=======================================\")\n",
        "    #print(param_v.data)\n",
        "    #print(param_v.grad.data)\n",
        "    f.write('epoch {}:  loss={} \\n'.format(epoch,  loss.data))\n",
        "    print('epoch {}:  loss={} \\n'.format(epoch, loss.data))\n",
        "\n",
        "    print('forward time={}'.format(en0-st))\n",
        "    print('backward time={}'.format(en1-en0))\n",
        "\n",
        "    param_v.grad.data.clamp_(-25,25)\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    arcsim.delete_mesh(sim.cloths[0].mesh)\n",
        "\n",
        "    scheduler.step(loss.item())\n",
        "\n",
        "    if epoch>=epochs:\n",
        "      break\n",
        "    epoch = epoch + 1\n",
        "\n",
        "with open(out_path+('/log%s.txt'%timestamp),'w',buffering=1) as f:\n",
        "  tot_step = 1\n",
        "  sim=arcsim.get_sim()\n",
        "  # reset_sim(sim)\n",
        "\n",
        "  #param_v = torch.zeros([steps, 4,3],dtype=torch.float64, requires_grad=True)\n",
        "  param_v = torch.tensor(trajectories/frame_time,dtype=torch.float64, requires_grad=True)\n",
        "\n",
        "  optimizer = torch.optim.Adam([param_v],lr=0.025)\n",
        "  scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.1, patience=0, verbose=True)\n",
        "\n",
        "  for cur_step in range(tot_step):\n",
        "    do_train(cur_step,optimizer,scheduler,sim,param_v)\n",
        "\n",
        "print(\"done\")\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "step\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "tensor([-1.0238,  1.0755,  0.2785], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5603, -1.7197,  0.2836], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.3985, -2.1977,  0.2902], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([1.0238, 1.3728, 0.2820], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "12\n",
            "tensor([-1.0184,  1.0752,  0.2506], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5583, -1.7184,  0.2589], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.3877, -2.1940,  0.2487], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([1.0126, 1.3720, 0.2419], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "13\n",
            "tensor([-1.0136,  1.0752,  0.2231], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5562, -1.7170,  0.2341], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.3771, -2.1909,  0.2075], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([1.0022, 1.3717, 0.2024], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "14\n",
            "tensor([-1.0087,  1.0751,  0.1953], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5541, -1.7151,  0.2088], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.3665, -2.1880,  0.1663], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([0.9914, 1.3713, 0.1624], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "15\n",
            "tensor([-1.0036,  1.0747,  0.1673], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5522, -1.7133,  0.1836], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.3559, -2.1851,  0.1250], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([0.9806, 1.3709, 0.1224], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "16\n",
            "tensor([-0.9983,  1.0739,  0.1391], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5497, -1.7113,  0.1582], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.3450, -2.1814,  0.0832], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([0.9699, 1.3702, 0.0821], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "17\n",
            "tensor([-0.9932,  1.0729,  0.1109], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5470, -1.7090,  0.1325], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.3342, -2.1783,  0.0416], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([0.9594, 1.3697, 0.0421], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "18\n",
            "tensor([-0.9883,  1.0718,  0.0828], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5445, -1.7066,  0.1066], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-3.2365e-01, -2.1757e+00,  4.8373e-04], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([0.9489, 1.3691, 0.0020], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "19\n",
            "tensor([-0.9836,  1.0710,  0.0548], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5424, -1.7047,  0.0810], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.3129, -2.1723, -0.0412], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.9387,  1.3686, -0.0380], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "20\n",
            "tensor([-0.9791,  1.0703,  0.0271], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5405, -1.7034,  0.0557], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.3022, -2.1681, -0.0833], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.9285,  1.3682, -0.0779], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "21\n",
            "tensor([-9.7481e-01,  1.0699e+00, -4.4914e-04], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5389, -1.7027,  0.0308], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.2915, -2.1642, -0.1251], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.9185,  1.3678, -0.1179], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "22\n",
            "tensor([-0.9707,  1.0697, -0.0279], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5374, -1.7023,  0.0060], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.2809, -2.1607, -0.1668], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.9087,  1.3676, -0.1575], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "23\n",
            "tensor([-0.9667,  1.0697, -0.0551], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5360, -1.7021, -0.0186], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.2703, -2.1570, -0.2084], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.8990,  1.3675, -0.1971], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "24\n",
            "tensor([-0.9628,  1.0699, -0.0823], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5348, -1.7022, -0.0431], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.2598, -2.1534, -0.2500], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.8892,  1.3675, -0.2367], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "25\n",
            "tensor([-0.9590,  1.0702, -0.1094], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5336, -1.7025, -0.0675], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.2494, -2.1497, -0.2916], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.8794,  1.3675, -0.2763], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "26\n",
            "tensor([-0.9553,  1.0706, -0.1364], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5325, -1.7030, -0.0918], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.2390, -2.1462, -0.3331], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.8697,  1.3677, -0.3158], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "27\n",
            "tensor([-0.9517,  1.0711, -0.1634], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5315, -1.7037, -0.1160], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.2288, -2.1427, -0.3745], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.8601,  1.3678, -0.3551], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "28\n",
            "tensor([-0.9481,  1.0717, -0.1902], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5307, -1.7046, -0.1401], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.2185, -2.1392, -0.4160], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.8505,  1.3679, -0.3945], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "29\n",
            "tensor([-0.9448,  1.0726, -0.2169], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5302, -1.7058, -0.1640], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.2083, -2.1358, -0.4574], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.8410,  1.3681, -0.4339], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "30\n",
            "tensor([-0.9415,  1.0737, -0.2436], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5300, -1.7072, -0.1877], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.1981, -2.1324, -0.4987], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.8315,  1.3685, -0.4732], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "31\n",
            "tensor([-0.9385,  1.0750, -0.2701], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5300, -1.7091, -0.2114], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.1880, -2.1289, -0.5400], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.8219,  1.3689, -0.5126], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "32\n",
            "tensor([-0.9357,  1.0766, -0.2966], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5302, -1.7114, -0.2350], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.1779, -2.1251, -0.5812], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.8124,  1.3694, -0.5519], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "33\n",
            "tensor([-0.9329,  1.0784, -0.3230], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5303, -1.7141, -0.2588], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.1677, -2.1210, -0.6224], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.8029,  1.3699, -0.5911], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "34\n",
            "tensor([-0.9300,  1.0803, -0.3493], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5303, -1.7167, -0.2824], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.1574, -2.1166, -0.6633], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.7934,  1.3701, -0.6304], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "35\n",
            "tensor([-0.9268,  1.0823, -0.3756], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5306, -1.7184, -0.3060], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.1474, -2.1126, -0.7042], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.7840,  1.3698, -0.6696], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "36\n",
            "tensor([-0.9238,  1.0841, -0.4010], dtype=torch.float64,\n",
            "       grad_fn=<SliceBackward>)\n",
            "tensor([ 0.5305, -1.7198, -0.3297], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.1376, -2.1089, -0.7450], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.7746,  1.3684, -0.7083], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "37\n",
            "tensor([-0.9253,  1.0840, -0.4180], dtype=torch.float64,\n",
            "       grad_fn=<SliceBackward>)\n",
            "tensor([ 0.5303, -1.7208, -0.3537], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.1279, -2.1053, -0.7858], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.7649,  1.3660, -0.7460], dtype=torch.float64,\n",
            "       grad_fn=<SliceBackward>)\n",
            "38\n",
            "tensor([-0.9309,  1.0819, -0.4274], dtype=torch.float64,\n",
            "       grad_fn=<SliceBackward>)\n",
            "tensor([ 0.5309, -1.7216, -0.3780], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.1209, -2.1017, -0.8265], dtype=torch.float64,\n",
            "       grad_fn=<SliceBackward>)\n",
            "tensor([ 0.7606,  1.3632, -0.7806], dtype=torch.float64,\n",
            "       grad_fn=<SliceBackward>)\n",
            "39\n",
            "tensor([-0.9393,  1.0784, -0.4321], dtype=torch.float64,\n",
            "       grad_fn=<SliceBackward>)\n",
            "tensor([ 0.5373, -1.7221, -0.3808], dtype=torch.float64,\n",
            "       grad_fn=<SliceBackward>)\n",
            "tensor([-0.1198, -2.0987, -0.8669], dtype=torch.float64,\n",
            "       grad_fn=<SliceBackward>)\n",
            "tensor([ 0.7761,  1.3597, -0.8076], dtype=torch.float64,\n",
            "       grad_fn=<SliceBackward>)\n",
            "=======================================\n",
            "epoch 0:  loss=810.2241191807343 \n",
            "\n",
            "forward time=104.54769706726074\n",
            "backward time=90.79960703849792\n",
            "step\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "tensor([-1.0238,  1.0755,  0.2785], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5603, -1.7197,  0.2836], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.3985, -2.1977,  0.2902], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([1.0238, 1.3728, 0.2820], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "12\n",
            "tensor([-1.0214,  1.0782,  0.2536], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5614, -1.7215,  0.2557], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.3908, -2.1971,  0.2456], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([1.0156, 1.3749, 0.2450], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "13\n",
            "tensor([-1.0194,  1.0811,  0.2289], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5623, -1.7229,  0.2339], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.3770, -2.1969,  0.2011], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([1.0080, 1.3776, 0.2083], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "14\n",
            "tensor([-1.0172,  1.0836,  0.2041], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5630, -1.7236,  0.2116], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.3694, -2.1970,  0.1567], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([1.0002, 1.3802, 0.1715], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "15\n",
            "tensor([-1.0146,  1.0858,  0.1789], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5636, -1.7240,  0.1891], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.3618, -2.1971,  0.1184], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([0.9922, 1.3826, 0.1344], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "16\n",
            "tensor([-1.0119,  1.0875,  0.1535], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5640, -1.7182,  0.1666], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.3542, -2.1968,  0.0738], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([0.9783, 1.3850, 0.0911], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "17\n",
            "tensor([-1.0092,  1.0889,  0.1280], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5642, -1.7183,  0.1439], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.3466, -2.1906,  0.0293], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([0.9643, 1.3873, 0.0479], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "18\n",
            "tensor([-1.0067,  1.0903,  0.1027], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5646, -1.7184,  0.1148], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.3388, -2.1897, -0.0157], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([0.9504, 1.3894, 0.0043], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "19\n",
            "tensor([-1.0044,  1.0916,  0.0775], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5654, -1.7130,  0.0862], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.3310, -2.1884, -0.0609], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.9371,  1.3919, -0.0388], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "20\n",
            "tensor([-1.0023,  1.0932,  0.0526], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5663, -1.7083,  0.0577], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.3233, -2.1812, -0.1059], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.9238,  1.3945, -0.0818], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "21\n",
            "tensor([-1.0006,  1.0952,  0.0279], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5673, -1.7103,  0.0294], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.3157, -2.1740, -0.1507], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.9106,  1.3972, -0.1247], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "22\n",
            "tensor([-0.9991,  1.0974,  0.0034], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 5.6848e-01, -1.7063e+00,  1.2540e-03], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.3082, -2.1668, -0.1955], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.8976,  1.4000, -0.1676], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "23\n",
            "tensor([-0.9978,  1.0999, -0.0210], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5697, -1.7087, -0.0268], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.3008, -2.1598, -0.2402], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.8846,  1.4029, -0.2104], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "24\n",
            "tensor([-0.9966,  1.1025, -0.0453], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5711, -1.7112, -0.0547], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.2935, -2.1528, -0.2848], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.8716,  1.4058, -0.2469], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "25\n",
            "tensor([-0.9956,  1.1050, -0.0696], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5724, -1.7138, -0.0765], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.2861, -2.1459, -0.3294], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.8587,  1.4089, -0.2834], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "26\n",
            "tensor([-0.9944,  1.1075, -0.0939], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5738, -1.7163, -0.1046], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.2788, -2.1392, -0.3739], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.8521,  1.4121, -0.3197], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "27\n",
            "tensor([-0.9934,  1.1101, -0.1180], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5754, -1.7191, -0.1324], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.2716, -2.1324, -0.4185], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.8456,  1.4153, -0.3559], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "28\n",
            "tensor([-0.9926,  1.1068, -0.1420], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5769, -1.7220, -0.1602], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.2643, -2.1258, -0.4630], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.8328,  1.4186, -0.3922], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "29\n",
            "tensor([-0.9919,  1.1038, -0.1658], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5786, -1.7252, -0.1880], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.2571, -2.1193, -0.5074], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.8201,  1.4221, -0.4285], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "30\n",
            "tensor([-0.9913,  1.1010, -0.1896], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5742, -1.7285, -0.2095], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.2498, -2.1130, -0.5518], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.8074,  1.4256, -0.4647], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "31\n",
            "tensor([-0.9908,  1.0984, -0.2133], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5698, -1.7319, -0.2308], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.2426, -2.1068, -0.5961], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.7947,  1.4292, -0.5009], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "32\n",
            "tensor([-0.9903,  1.1020, -0.2433], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5654, -1.7353, -0.2584], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.2355, -2.1009, -0.6405], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.7820,  1.4327, -0.5371], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "33\n",
            "tensor([-0.9900,  1.1057, -0.2732], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5611, -1.7327, -0.2795], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.2284, -2.0950, -0.6848], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.7693,  1.4364, -0.5732], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "34\n",
            "tensor([-0.9897,  1.1096, -0.3030], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5570, -1.7306, -0.3005], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.2149, -2.0891, -0.7291], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.7566,  1.4401, -0.6089], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "35\n",
            "tensor([-0.9892,  1.1136, -0.3327], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5591, -1.7350, -0.3279], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.2016, -2.0831, -0.7732], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.7502,  1.4436, -0.6442], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "36\n",
            "tensor([-0.9883,  1.1178, -0.3622], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5613, -1.7332, -0.3551], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.1885, -2.0767, -0.8173], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.7435,  1.4469, -0.6789], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "37\n",
            "tensor([-0.9864,  1.1221, -0.3915], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5637, -1.7312, -0.3761], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.1756, -2.0704, -0.8614], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.7363,  1.4499, -0.7131], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "38\n",
            "tensor([-0.9834,  1.1267, -0.4204], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5689, -1.7289, -0.3869], dtype=torch.float64,\n",
            "       grad_fn=<SliceBackward>)\n",
            "tensor([-0.1626, -2.0643, -0.9056], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.7410,  1.4536, -0.7397], dtype=torch.float64,\n",
            "       grad_fn=<SliceBackward>)\n",
            "39\n",
            "tensor([-0.9822,  1.1307, -0.4455], dtype=torch.float64,\n",
            "       grad_fn=<SliceBackward>)\n",
            "tensor([ 0.5778, -1.7260, -0.3897], dtype=torch.float64,\n",
            "       grad_fn=<SliceBackward>)\n",
            "tensor([-0.1492, -2.0580, -0.9498], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.7526,  1.4569, -0.7632], dtype=torch.float64,\n",
            "       grad_fn=<SliceBackward>)\n",
            "=======================================\n",
            "epoch 1:  loss=798.006371373932 \n",
            "\n",
            "forward time=107.23324513435364\n",
            "backward time=91.6951973438263\n",
            "step\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "tensor([-1.0238,  1.0755,  0.2785], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5603, -1.7197,  0.2836], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.3985, -2.1977,  0.2902], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([1.0238, 1.3728, 0.2820], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "12\n",
            "tensor([-1.0212,  1.0780,  0.2534], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5612, -1.7243,  0.2556], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.3906, -2.1970,  0.2457], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([1.0187, 1.3748, 0.2449], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "13\n",
            "tensor([-1.0189,  1.0821,  0.2285], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5620, -1.7252,  0.2335], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.3767, -2.1968,  0.1982], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([1.0138, 1.3798, 0.2108], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "14\n",
            "tensor([-1.0165,  1.0846,  0.2035], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5626, -1.7265,  0.2114], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.3691, -2.1968,  0.1541], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([1.0090, 1.3840, 0.1747], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "15\n",
            "tensor([-1.0137,  1.0868,  0.1780], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5629, -1.7301,  0.1888], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.3612, -2.1966,  0.1168], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([1.0032, 1.3889, 0.1394], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "16\n",
            "tensor([-1.0106,  1.0885,  0.1516], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5631, -1.7208,  0.1660], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.3533, -2.1992,  0.0723], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([0.9888, 1.3909, 0.0942], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "17\n",
            "tensor([-1.0076,  1.0898,  0.1242], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5633, -1.7207,  0.1431], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.3454, -2.1895,  0.0252], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([0.9741, 1.3959, 0.0501], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "18\n",
            "tensor([-1.0049,  1.0910,  0.0978], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5636, -1.7205,  0.1111], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.3377, -2.1895, -0.0217], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([0.9597, 1.4000, 0.0044], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "19\n",
            "tensor([-1.0025,  1.0924,  0.0726], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5639, -1.7115,  0.0791], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.3297, -2.1896, -0.0693], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.9460,  1.4046, -0.0410], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "20\n",
            "tensor([-1.0003,  1.0941,  0.0467], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5643, -1.7031,  0.0484], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.3220, -2.1803, -0.1170], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.9329,  1.4086, -0.0868], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "21\n",
            "tensor([-0.9989,  1.0961,  0.0221], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5652, -1.7044,  0.0167], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.3143, -2.1710, -0.1646], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.9204,  1.4136, -0.1292], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "22\n",
            "tensor([-0.9976,  1.0984, -0.0024], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5662, -1.6970, -0.0146], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.3067, -2.1612, -0.2126], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.9084,  1.4179, -0.1722], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "23\n",
            "tensor([-0.9967,  1.1009, -0.0270], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5674, -1.6991, -0.0459], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.2973, -2.1512, -0.2605], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.8965,  1.4225, -0.2155], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "24\n",
            "tensor([-0.9982,  1.1035, -0.0493], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5687, -1.6998, -0.0772], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.2895, -2.1412, -0.3083], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.8826,  1.4269, -0.2489], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "25\n",
            "tensor([-0.9985,  1.1062, -0.0730], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5701, -1.7022, -0.0991], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.2800, -2.1314, -0.3560], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.8686,  1.4307, -0.2828], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "26\n",
            "tensor([-1.0003,  1.1089, -0.0944], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5713, -1.7075, -0.1292], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.2708, -2.1216, -0.4036], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.8644,  1.4342, -0.3169], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "27\n",
            "tensor([-1.0011,  1.1119, -0.1174], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5736, -1.7106, -0.1593], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.2617, -2.1121, -0.4511], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.8606,  1.4374, -0.3510], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "28\n",
            "tensor([-1.0024,  1.1063, -0.1383], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5766, -1.7134, -0.1896], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.2553, -2.1028, -0.4986], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.8501,  1.4406, -0.3850], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "29\n",
            "tensor([-1.0032,  1.1006, -0.1632], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5802, -1.7192, -0.2199], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.2496, -2.0936, -0.5460], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.8390,  1.4439, -0.4187], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "30\n",
            "tensor([-1.0037,  1.0951, -0.1843], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5734, -1.7236, -0.2398], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.2441, -2.0845, -0.5933], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.8283,  1.4464, -0.4519], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "31\n",
            "tensor([-1.0040,  1.0904, -0.2095], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5664, -1.7284, -0.2604], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.2387, -2.0757, -0.6405], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.8177,  1.4490, -0.4851], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "32\n",
            "tensor([-1.0045,  1.0922, -0.2379], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5588, -1.7332, -0.2915], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.2331, -2.0669, -0.6873], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.8071,  1.4507, -0.5183], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "33\n",
            "tensor([-1.0056,  1.0945, -0.2659], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5515, -1.7266, -0.3148], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.2270, -2.0582, -0.7343], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.7965,  1.4526, -0.5515], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "34\n",
            "tensor([-1.0076,  1.0967, -0.2940], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5445, -1.7214, -0.3357], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.2108, -2.0496, -0.7812], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.7860,  1.4546, -0.5845], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "35\n",
            "tensor([-1.0102,  1.0998, -0.3225], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5472, -1.7272, -0.3658], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.1952, -2.0412, -0.8277], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.7821,  1.4565, -0.6173], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "36\n",
            "tensor([-1.0128,  1.1034, -0.3526], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5528, -1.7238, -0.3848], dtype=torch.float64,\n",
            "       grad_fn=<SliceBackward>)\n",
            "tensor([-0.1790, -2.0326, -0.8735], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.7785,  1.4586, -0.6495], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "37\n",
            "tensor([-1.0151,  1.1085, -0.3848], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5599, -1.7191, -0.3869], dtype=torch.float64,\n",
            "       grad_fn=<SliceBackward>)\n",
            "tensor([-0.1622, -2.0233, -0.9185], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.7747,  1.4613, -0.6813], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "38\n",
            "tensor([-1.0167,  1.1134, -0.4171], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5681, -1.7150, -0.3877], dtype=torch.float64,\n",
            "       grad_fn=<SliceBackward>)\n",
            "tensor([-0.1456, -2.0144, -0.9634], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.7615,  1.4641, -0.7123], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "39\n",
            "tensor([-1.0169,  1.1173, -0.4493], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5759, -1.7109, -0.3907], dtype=torch.float64,\n",
            "       grad_fn=<SliceBackward>)\n",
            "tensor([-0.1288, -2.0084, -1.0083], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.7464,  1.4662, -0.7428], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "=======================================\n",
            "epoch 2:  loss=764.7436600029432 \n",
            "\n",
            "forward time=104.42571878433228\n",
            "backward time=91.11274003982544\n",
            "step\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "tensor([-1.0238,  1.0755,  0.2785], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5603, -1.7197,  0.2836], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.3985, -2.1977,  0.2902], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([1.0238, 1.3728, 0.2820], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "12\n",
            "tensor([-1.0222,  1.0768,  0.2522], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5622, -1.7250,  0.2568], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.3917, -2.1980,  0.2470], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([1.0195, 1.3735, 0.2436], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "13\n",
            "tensor([-1.0187,  1.0802,  0.2260], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5640, -1.7268,  0.2357], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.3790, -2.1967,  0.1964], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([1.0151, 1.3786, 0.2098], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "14\n",
            "tensor([-1.0159,  1.0815,  0.1998], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5657, -1.7270,  0.2145], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.3724, -2.1957,  0.1513], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([1.0109, 1.3824, 0.1729], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "15\n",
            "tensor([-1.0119,  1.0825,  0.1730], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5662, -1.7311,  0.1907], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.3631, -2.1961,  0.1159], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([1.0048, 1.3876, 0.1372], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "16\n",
            "tensor([-1.0077,  1.0831,  0.1448], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5675, -1.7216,  0.1692], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.3538, -2.2015,  0.0725], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([0.9893, 1.3883, 0.0897], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "17\n",
            "tensor([-1.0037,  1.0834,  0.1150], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5665, -1.7206,  0.1452], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.3454, -2.1891,  0.0227], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([0.9732, 1.3933, 0.0436], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "18\n",
            "tensor([-1.0001,  1.0836,  0.0869], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5657, -1.7193,  0.1101], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.3388, -2.1902, -0.0239], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.9588,  1.3973, -0.0036], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "19\n",
            "tensor([-0.9970,  1.0840,  0.0605], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5665, -1.7078,  0.0752], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.3314, -2.1879, -0.0727], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.9453,  1.4015, -0.0512], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "20\n",
            "tensor([-0.9941,  1.0846,  0.0328], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5684, -1.6972,  0.0426], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.3247, -2.1749, -0.1212], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.9323,  1.4049, -0.0996], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "21\n",
            "tensor([-0.9921,  1.0857,  0.0072], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5688, -1.6977,  0.0091], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.3182, -2.1629, -0.1694], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.9193,  1.4094, -0.1440], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "22\n",
            "tensor([-0.9906,  1.0871, -0.0181], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5685, -1.6877, -0.0229], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.3114, -2.1512, -0.2175], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.9079,  1.4133, -0.1888], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "23\n",
            "tensor([-0.9898,  1.0890, -0.0433], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5705, -1.6887, -0.0553], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.2999, -2.1396, -0.2655], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.8972,  1.4176, -0.2334], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "24\n",
            "tensor([-0.9924,  1.0911, -0.0652], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5726, -1.6873, -0.0875], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.2920, -2.1278, -0.3135], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.8825,  1.4217, -0.2668], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "25\n",
            "tensor([-0.9925,  1.0935, -0.0896], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5746, -1.6886, -0.1095], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.2800, -2.1160, -0.3616], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.8673,  1.4252, -0.3017], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "26\n",
            "tensor([-0.9954,  1.0959, -0.1099], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5763, -1.6942, -0.1411], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.2717, -2.1042, -0.4117], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.8652,  1.4281, -0.3346], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "27\n",
            "tensor([-0.9964,  1.0986, -0.1330], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5796, -1.6962, -0.1726], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.2635, -2.0924, -0.4619], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.8643,  1.4304, -0.3676], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "28\n",
            "tensor([-0.9983,  1.0911, -0.1527], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5838, -1.6985, -0.2048], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.2578, -2.0808, -0.5121], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.8564,  1.4329, -0.4002], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "29\n",
            "tensor([-0.9997,  1.0832, -0.1792], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5886, -1.7059, -0.2369], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.2529, -2.0695, -0.5622], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.8477,  1.4356, -0.4321], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "30\n",
            "tensor([-1.0010,  1.0764, -0.2001], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5801, -1.7114, -0.2551], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.2486, -2.0582, -0.6119], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.8395,  1.4370, -0.4629], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "31\n",
            "tensor([-1.0013,  1.0703, -0.2272], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5711, -1.7179, -0.2742], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.2447, -2.0470, -0.6614], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.8315,  1.4383, -0.4933], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "32\n",
            "tensor([-1.0022,  1.0704, -0.2567], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5615, -1.7245, -0.3063], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.2404, -2.0357, -0.7101], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.8235,  1.4385, -0.5236], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "33\n",
            "tensor([-1.0041,  1.0718, -0.2839], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5528, -1.7162, -0.3287], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.2352, -2.0244, -0.7581], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.8156,  1.4392, -0.5537], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "34\n",
            "tensor([-1.0075,  1.0726, -0.3111], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5445, -1.7107, -0.3478], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.2154, -2.0130, -0.8067], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.8078,  1.4401, -0.5837], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "35\n",
            "tensor([-1.0121,  1.0749, -0.3392], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5476, -1.7200, -0.3763], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.1969, -2.0025, -0.8540], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.8067,  1.4409, -0.6135], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "36\n",
            "tensor([-1.0170,  1.0776, -0.3703], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5563, -1.7184, -0.3860], dtype=torch.float64,\n",
            "       grad_fn=<SliceBackward>)\n",
            "tensor([-0.1776, -1.9914, -0.9010], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.8061,  1.4420, -0.6430], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "37\n",
            "tensor([-1.0221,  1.0846, -0.4051], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5632, -1.7142, -0.3886], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.1666, -1.9822, -0.9473], dtype=torch.float64,\n",
            "       grad_fn=<SliceBackward>)\n",
            "tensor([ 0.8054,  1.4442, -0.6724], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "38\n",
            "tensor([-1.0270,  1.0921, -0.4401], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5722, -1.7090, -0.3899], dtype=torch.float64,\n",
            "       grad_fn=<SliceBackward>)\n",
            "tensor([-0.1600, -1.9762, -0.9936], dtype=torch.float64,\n",
            "       grad_fn=<SliceBackward>)\n",
            "tensor([ 0.7958,  1.4488, -0.7023], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "39\n",
            "tensor([-1.0313,  1.0979, -0.4751], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5824, -1.7026, -0.3874], dtype=torch.float64,\n",
            "       grad_fn=<SliceBackward>)\n",
            "tensor([-0.1444, -1.9751, -1.0398], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.7848,  1.4529, -0.7330], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "=======================================\n",
            "epoch 3:  loss=689.7503974624187 \n",
            "\n",
            "forward time=108.96817445755005\n",
            "backward time=92.56962847709656\n",
            "step\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "tensor([-1.0238,  1.0755,  0.2785], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5603, -1.7197,  0.2836], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.3985, -2.1977,  0.2902], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([1.0238, 1.3728, 0.2820], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "12\n",
            "tensor([-1.0238,  1.0750,  0.2522], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([ 0.5620, -1.7247,  0.2568], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([-0.3915, -2.1994,  0.2468], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([1.0191, 1.3717, 0.2437], dtype=torch.float64, grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-6ce19e995eb4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mcur_step\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtot_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     \u001b[0mdo_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparam_v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"done\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-6ce19e995eb4>\u001b[0m in \u001b[0;36mdo_train\u001b[0;34m(cur_step, optimizer, scheduler, sim, param_v)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0mreset_sim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_sim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m     \u001b[0men0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-6ce19e995eb4>\u001b[0m in \u001b[0;36mrun_sim\u001b[0;34m(steps, sim, param_v)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobstacles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurr_state_mesh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcloths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmesh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#* (1 + ((step-pre_steps)/steps))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0marcsim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msim_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/diffsim/pysim/taucs_py.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, A, b, ind)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mTaucsFunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFunction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                 \u001b[0;31m#print(A)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7UQakPmSnUz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1112f547-d985-49f4-f20a-7b9af36cadaf"
      },
      "source": [
        "%cd /content/diffsim/pysim"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/diffsim/pysim\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vfv_qpCo0oy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1ab8215-7d66-4011-853f-3025642a32a7"
      },
      "source": [
        "%%writefile visualize.py\n",
        "import torch\n",
        "import arcsim\n",
        "\n",
        "with torch.autograd.profiler.profile() as prof:\n",
        "\t  arcsim.msim(4,['arcsim','replay','/content/default_out/out', '/content/default_out/out'])\n",
        "print(prof)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting visualize.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZgv6QBdvesu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ad05a28-82ba-444e-ce2e-df017ba1c52d"
      },
      "source": [
        "!xvfb-run -s \"-screen 0 1280x720x24 -ac +extension GLX +render -noreset\" python visualize.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "main\n",
            "4\n",
            "arcsim replay /content/default_out/out\n",
            "reply 1 \n",
            "reply 2 \n",
            "reply 3 \n",
            "reply 4 \n",
            "reply 5 \n",
            "reply 6 \n",
            "/content/default_out/out/0000_\n",
            "/content/default_out/out/0000_rig\n",
            "reply 7 \n",
            "/content/default_out/out/0000.bmp\n",
            "/content/default_out/out/0001_\n",
            "/content/default_out/out/0001_rig\n",
            "/content/default_out/out/0001.bmp\n",
            "/content/default_out/out/0002_\n",
            "/content/default_out/out/0002_rig\n",
            "/content/default_out/out/0002.bmp\n",
            "/content/default_out/out/0003_\n",
            "/content/default_out/out/0003_rig\n",
            "/content/default_out/out/0003.bmp\n",
            "/content/default_out/out/0004_\n",
            "/content/default_out/out/0004_rig\n",
            "/content/default_out/out/0004.bmp\n",
            "/content/default_out/out/0005_\n",
            "/content/default_out/out/0005_rig\n",
            "/content/default_out/out/0005.bmp\n",
            "/content/default_out/out/0006_\n",
            "/content/default_out/out/0006_rig\n",
            "/content/default_out/out/0006.bmp\n",
            "/content/default_out/out/0007_\n",
            "/content/default_out/out/0007_rig\n",
            "/content/default_out/out/0007.bmp\n",
            "/content/default_out/out/0008_\n",
            "/content/default_out/out/0008_rig\n",
            "/content/default_out/out/0008.bmp\n",
            "/content/default_out/out/0009_\n",
            "/content/default_out/out/0009_rig\n",
            "/content/default_out/out/0009.bmp\n",
            "/content/default_out/out/0010_\n",
            "/content/default_out/out/0010_rig\n",
            "/content/default_out/out/0010.bmp\n",
            "/content/default_out/out/0011_\n",
            "/content/default_out/out/0011_rig\n",
            "/content/default_out/out/0011.bmp\n",
            "/content/default_out/out/0012_\n",
            "/content/default_out/out/0012_rig\n",
            "/content/default_out/out/0012.bmp\n",
            "/content/default_out/out/0013_\n",
            "/content/default_out/out/0013_rig\n",
            "/content/default_out/out/0013.bmp\n",
            "/content/default_out/out/0014_\n",
            "/content/default_out/out/0014_rig\n",
            "/content/default_out/out/0014.bmp\n",
            "/content/default_out/out/0015_\n",
            "/content/default_out/out/0015_rig\n",
            "/content/default_out/out/0015.bmp\n",
            "/content/default_out/out/0016_\n",
            "/content/default_out/out/0016_rig\n",
            "/content/default_out/out/0016.bmp\n",
            "/content/default_out/out/0017_\n",
            "/content/default_out/out/0017_rig\n",
            "/content/default_out/out/0017.bmp\n",
            "/content/default_out/out/0018_\n",
            "/content/default_out/out/0018_rig\n",
            "/content/default_out/out/0018.bmp\n",
            "/content/default_out/out/0019_\n",
            "/content/default_out/out/0019_rig\n",
            "/content/default_out/out/0019.bmp\n",
            "/content/default_out/out/0020_\n",
            "/content/default_out/out/0020_rig\n",
            "/content/default_out/out/0020.bmp\n",
            "/content/default_out/out/0021_\n",
            "/content/default_out/out/0021_rig\n",
            "/content/default_out/out/0021.bmp\n",
            "/content/default_out/out/0022_\n",
            "/content/default_out/out/0022_rig\n",
            "/content/default_out/out/0022.bmp\n",
            "/content/default_out/out/0023_\n",
            "/content/default_out/out/0023_rig\n",
            "/content/default_out/out/0023.bmp\n",
            "/content/default_out/out/0024_\n",
            "/content/default_out/out/0024_rig\n",
            "/content/default_out/out/0024.bmp\n",
            "/content/default_out/out/0025_\n",
            "/content/default_out/out/0025_rig\n",
            "/content/default_out/out/0025.bmp\n",
            "/content/default_out/out/0026_\n",
            "/content/default_out/out/0026_rig\n",
            "/content/default_out/out/0026.bmp\n",
            "/content/default_out/out/0027_\n",
            "/content/default_out/out/0027_rig\n",
            "/content/default_out/out/0027.bmp\n",
            "/content/default_out/out/0028_\n",
            "/content/default_out/out/0028_rig\n",
            "/content/default_out/out/0028.bmp\n",
            "/content/default_out/out/0029_\n",
            "/content/default_out/out/0029_rig\n",
            "/content/default_out/out/0029.bmp\n",
            "/content/default_out/out/0030_\n",
            "/content/default_out/out/0030_rig\n",
            "/content/default_out/out/0030.bmp\n",
            "/content/default_out/out/0031_\n",
            "/content/default_out/out/0031_rig\n",
            "/content/default_out/out/0031.bmp\n",
            "/content/default_out/out/0032_\n",
            "/content/default_out/out/0032_rig\n",
            "/content/default_out/out/0032.bmp\n",
            "/content/default_out/out/0033_\n",
            "/content/default_out/out/0033_rig\n",
            "/content/default_out/out/0033.bmp\n",
            "/content/default_out/out/0034_\n",
            "/content/default_out/out/0034_rig\n",
            "/content/default_out/out/0034.bmp\n",
            "/content/default_out/out/0035_\n",
            "/content/default_out/out/0035_rig\n",
            "/content/default_out/out/0035.bmp\n",
            "/content/default_out/out/0036_\n",
            "/content/default_out/out/0036_rig\n",
            "/content/default_out/out/0036.bmp\n",
            "/content/default_out/out/0037_\n",
            "/content/default_out/out/0037_rig\n",
            "/content/default_out/out/0037.bmp\n",
            "/content/default_out/out/0038_\n",
            "/content/default_out/out/0038_rig\n",
            "/content/default_out/out/0038.bmp\n",
            "/content/default_out/out/0039_\n",
            "/content/default_out/out/0039_rig\n",
            "/content/default_out/out/0039.bmp\n",
            "/content/default_out/out/0040_\n",
            "/content/default_out/out/0040_rig\n",
            "/content/default_out/out/0040.bmp\n",
            "/content/default_out/out/0041_\n",
            "/content/default_out/out/0041_rig\n",
            "Error: failed to open file /content/default_out/out/0041_000.obj\n",
            "Error: failed to open file /content/default_out/out/0041_rig000.obj\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMJg6QBfLhkY"
      },
      "source": [
        "import pathlib\n",
        "%matplotlib inline\n",
        "\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "frames = []\n",
        "for bmp_file in sorted(list(pathlib.Path('/content/default_out/out').glob('*.bmp'))):\n",
        "    frames.append(plt.imread(bmp_file))\n",
        "    #print(bmp_file)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGK4qlb9LUWy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        },
        "outputId": "f7c49278-2805-4293-f92c-1d047f81553d"
      },
      "source": [
        "from matplotlib import animation, rc\n",
        "from IPython.display import HTML\n",
        "\n",
        "fig = plt.figure()\n",
        "\n",
        "ims = []\n",
        "for i in range(len(frames)):\n",
        "    im = plt.imshow(frames[i], animated=True)\n",
        "    ims.append([im])\n",
        "\n",
        "ani = animation.ArtistAnimation(fig, ims, interval=50, blit=True,\n",
        "                                repeat_delay=1000)\n",
        "\n",
        "rc('animation', html='jshtml')\n",
        "ani"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "id": "WT4BylaM-HQp",
        "outputId": "d7e95c96-9230-4ea5-b737-bc97b9837c0e"
      },
      "source": [
        "HTML(ani.to_html5_video())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video width=\"432\" height=\"288\" controls autoplay loop>\n",
              "  <source type=\"video/mp4\" src=\"data:video/mp4;base64,AAAAHGZ0eXBNNFYgAAACAGlzb21pc28yYXZjMQAAAAhmcmVlAABQom1kYXQAAAKuBgX//6rcRem9\n",
              "5tlIt5Ys2CDZI+7veDI2NCAtIGNvcmUgMTUyIHIyODU0IGU5YTU5MDMgLSBILjI2NC9NUEVHLTQg\n",
              "QVZDIGNvZGVjIC0gQ29weWxlZnQgMjAwMy0yMDE3IC0gaHR0cDovL3d3dy52aWRlb2xhbi5vcmcv\n",
              "eDI2NC5odG1sIC0gb3B0aW9uczogY2FiYWM9MSByZWY9MyBkZWJsb2NrPTE6MDowIGFuYWx5c2U9\n",
              "MHgzOjB4MTEzIG1lPWhleCBzdWJtZT03IHBzeT0xIHBzeV9yZD0xLjAwOjAuMDAgbWl4ZWRfcmVm\n",
              "PTEgbWVfcmFuZ2U9MTYgY2hyb21hX21lPTEgdHJlbGxpcz0xIDh4OGRjdD0xIGNxbT0wIGRlYWR6\n",
              "b25lPTIxLDExIGZhc3RfcHNraXA9MSBjaHJvbWFfcXBfb2Zmc2V0PS0yIHRocmVhZHM9NiBsb29r\n",
              "YWhlYWRfdGhyZWFkcz0xIHNsaWNlZF90aHJlYWRzPTAgbnI9MCBkZWNpbWF0ZT0xIGludGVybGFj\n",
              "ZWQ9MCBibHVyYXlfY29tcGF0PTAgY29uc3RyYWluZWRfaW50cmE9MCBiZnJhbWVzPTMgYl9weXJh\n",
              "bWlkPTIgYl9hZGFwdD0xIGJfYmlhcz0wIGRpcmVjdD0xIHdlaWdodGI9MSBvcGVuX2dvcD0wIHdl\n",
              "aWdodHA9MiBrZXlpbnQ9MjUwIGtleWludF9taW49MjAgc2NlbmVjdXQ9NDAgaW50cmFfcmVmcmVz\n",
              "aD0wIHJjX2xvb2thaGVhZD00MCByYz1jcmYgbWJ0cmVlPTEgY3JmPTIzLjAgcWNvbXA9MC42MCBx\n",
              "cG1pbj0wIHFwbWF4PTY5IHFwc3RlcD00IGlwX3JhdGlvPTEuNDAgYXE9MToxLjAwAIAAAAkeZYiE\n",
              "ADv//vdOvwKbRZdqA5JXCvbKpCZZuVJrAfKmAAADAAARsG58lw15q9IkAACxXj4Lxf+AD0w2upaU\n",
              "5NgdHwIwwtrCa71T5MAR1tjRw41wu/+qAjp0HKQUJQSJZg1gW7TGu79WO1pPHT9zT21bOkuRMk5D\n",
              "Isc8e1rvXd7JOgt41+M6i+xLeJ0tIWUSjA4Q4/PXkIX2o2+tfOEEoRjMn6H4zbQ/ynIXtBAhuyMd\n",
              "npPeaNQdpdaE6ci+NUA7ieiob7fX3s+S+bgGZeCiqaVQjTb8VocxHxerkwLeCFBEOLvUgvqlurEy\n",
              "asHOu16NQak+24RSV+IE1jMKIFSiBVpYUmAgkfCy+6RdryyRe7GdOpwc8FN6Zt1jiLuo6dxvHPjM\n",
              "VWDUkV28cSXmTWm23x3Hh1Hdza1UbpGQ8Wtu7LF2ZW8IoVuZ8cdSsk/tbP54Laj3r5B17CF2sIYO\n",
              "+fF8CkAsrGxsiz2BBxYecZ+AACllwpnQXeVmqUAABu/jC5oSSc+BDap+Q6YTClCMO/RVgh/0MwhW\n",
              "7SWe2vX/f3fqWFVivD/7sD9Vt2dv5Jnv85RO6wZ8FZYhUNyZTOn/m7l+608W5GDp3g9OmcHTX54F\n",
              "rNNg4Wz02EioFSO61dQlwtL7h28t6/cxPtgYKOdhkqV0ezwJantXJupW0hPhUtJkdvpjOoDYlMDD\n",
              "nm0bDRoMH3SvLHran9oLWQmbg2nTectYZS2ZW26nV1EY/i2G4ACn7+mGqjUn28aHlGT3qgnDaTTQ\n",
              "0yIYfJR7LEv4vBrI9ocuNpoJXMkADqY3pD7ywfGjgyUj3FSd8kktuta+IbPZYzN9YTnIAPXwXrar\n",
              "oHgdU4sy/sKxLZra8hgVnRZ8tT3JUWWylFrZ/FWsM1a6BJetIwgTfcSfcR3APGjTxQEPmrzCvw0j\n",
              "DPu26R1vpV3iZuPYfF1DY1gYHrUfNPkKmOHHQooUtxC7yEtrFnQKia/4WG5SdJ50xN0nU58IwFd5\n",
              "WFd7Zvr36Hiljf4Z0ZgWSwfJDZEa0Jrk5c7mBdmuhZZ18M2iWfxWjggMneb+bJYbeUW2qRP13UoX\n",
              "l0uFd9tflQzDOWz1y76/Wbh6yz+5uvKgdywOV5Ojqzfylct2CswERNV1mbnVNhxydJW1B8rmWC/A\n",
              "RHzsACYni5PLF6I6CjSVXkwU1OdTwQ1dzwet38d3s6vik/UASBofpxdA4E8v8FX2POumsOt9630m\n",
              "bl7QdyR4FLPBS1sDN91SFOfPFtgrh37u8g/nx8sNEG+veeIgMssI9cTePjnyH6hgbjyFWa8r9J4y\n",
              "JTIQXnDNwWiwA+pM/6yPwP2/uJXaye4g6AAvWt642dM3YU7/RAbvzBGfSfmhc+tF9wEm1OEMtO9g\n",
              "buBG4mqk1r5UwzHhzjw4IxFN8Vfuqex5kykMqgl3GUUdsZN8O77SJQm5qRo7lK6UnGyR6ynaDjoO\n",
              "KqI3CqrHU0o0IsbEaZOSbz3KtgQpl+rn2koE2rsBZh3aGNCnAiltRmpftl/QRsGMaQFpiYfZbGVp\n",
              "iyrRG4qsH2+9OG4oE1KJLDmhUEBvuDJn5Ja2brWnvzFECwYxiRtLQVa5pvtM+GqYCx6Rcx233/uA\n",
              "RS3vS5Wc75C35PE2lWVRkBl6X+OPvjVYz9SE8z8kna1lTXwjE3kWWC//B1q88ZezshKzjD+OicjJ\n",
              "UW9eKvOGW+C5Tene+tEjrS2ywZcobiMEaqU62829AJPukJADMvORXUPZvcAMD/kPnq1N8ao9oD7S\n",
              "UyeEPbnvM36yY8doqRC6CEQ1sT0Kiio7N3jmfwqqHDEcdxJLyVm7/ziAv08g0UGadjh7WiHWq2Sr\n",
              "huRCW0nqRquxKq6oMPx7+TUB9kgkbw35LZzUpQBOiylUQCN4Aw/ONu6+bQhDiMKd4Bp8egGAG02v\n",
              "Jb+8l4+xDa6gE1WW7GEUyY5V1aHReDraDz+1EKRtM/GHNJONKnUh2DsrQt3a16vSj+rMshZqlO6B\n",
              "pS2zGE6ieX4J4/0R3MrTWdW4Pyz6LPqlWHj8EBxW21qRawwyxHyfQFvbYcPkshGrzUN8xb1ssa/m\n",
              "vxoWs69ExMufjC14BK1Mt37vjPgat7tCgwmqo/IXfVElbdx7prMvlzzq8lOcYihVMOVtKpJzdRc6\n",
              "6rR4fSclKg6Cu1QdXjxPH0WtUfBuBWVGAfFgZ6qf5sA4Arimb9Vf+jQ6Xa7d4LJUz5y3fcH+zxJD\n",
              "9iwn0VNC3M7MZVAUczMv9KJ0/D+PlCCwcqOSMM3eEli58wBrKywkVt/Ln1qx5tZctem+PU4zVEY0\n",
              "Z2GmTj0tWhyRE6IjgrBwHdnrq1P1UVzXEY1k/W2Ai1ihOlgnKzX9D4ElMfFfItu63ap0FLXI0Lgk\n",
              "i3mPieWC4blOGa/0Ln7A/1tWGS2aV3fUo1zUBgpIjZlqX0DdsvQ3HDmOXyGaLXJCiFnCB2zd2NXe\n",
              "8405enphnszZCPFWIAimWHFFf35SEsPHK19NdlyRvaDPgpI9vNKCmccIi0BDYN6Q59hB4UM9bIr2\n",
              "nlQfZjAjtWia+w4dwestF8XL3m2ez7DnIIO7C1nxbXdAWMHQOegC4iyl3kutiIY1dD9IXGlCxdGO\n",
              "T9f55bPuNbyQ4FuGDMQSAwMTWCVk3lbeY59uyjn3TC2EQqmGmGUW3IyxIMVESNiwyhQ3VOQVFZkQ\n",
              "s8lc3Mnwv/0/BbtlbR4QpcMXZEISmFuSXHxcEcBXEjTy6ME/NXCE/HN5/gOeGHAn/OcF1dJVpZVy\n",
              "puVvGg82jksHlIKdu7+pebURVLBz61AffWgbbnSkWQin0aEQuMLKzlRKGPFH8oyBhuxlU3zwLyFE\n",
              "bIRA2CSgHfEWUD0V8q77i3jdgfhRMmOaBEaJcj3po2j1e8i43cbWGP0EpuuJgYSLQB2dZB8GCwa4\n",
              "Vqked2VP3tBwOef624hAEn6NGQqLazlwsruY9HrsaR7LGUz9ivKxgGb4kS9lHpGQ8SMUv9oVeHyw\n",
              "2XlqtmOiT0rFgdlb+XL3w32upLeV6L4uBT1eJQrVmuw8kAqkPkIuAxlPb9Y3jQplOnU6S3rP+M5J\n",
              "hSpG1n0fz3uTgDBp7oksckCNDiHA4/sRo2ABq/SNVD0POP3GRtdOblBAJfAN0GAPUANjAAAWzkGa\n",
              "IWxD//6plgCA/MTquuyX/z7rEAk/VMenQkiHz6+3FGXQsSXpaEZKxWanASxz+CjgwAvxDxDqPfMA\n",
              "1ZuoLVnzwzVOqbmgYJhbGLn9lvweeytnVM7hJdKAFANGdkQdelnqHLbg1ozQCQsGQJcdL437FV9D\n",
              "fa3xoKU61S8YEldyMdLr72Hu+sYadg8kHtdMC8stcTLRHR3kQ480FDpHtiU1h/sQjqGc3FFHzypH\n",
              "SSMqmN6ZTNCmn8MLK9SNTQgEVEG3yIJB5r7Qudhb6ocl1a30oc86RSrcYOpG+MUV15VuIGzSm4R5\n",
              "IYp/yW3jcHJCH98nztuZufvQ66q/b9ziUyfx1NGZ235CHEtBOj6a8gFv402MhuIgvpo/sECiYon1\n",
              "DCQxUddgsVF1rIPzCV+XX68JFdrdjihQSwupL5D5RbmKtYa6rj8GRbK//J8TyKLfJB/K99ntmep8\n",
              "aiopURkl+L6jU8AmEcozIebdREGH+aekiITSEsMNPPbIRh7O2Ci46W7hhBdF2Wyj5/RpamFW0ksN\n",
              "q7Q1lctw2DdRsvCZ0hsznR3JuKygmwJUNf7iVMRNa0o984K6XiMNjvvjyRRgG++YrmvDgZ4SB9Ua\n",
              "3JsxPraSF5XlW6bLq1SgN+ibIf6rA6Dh4X06C6Fjhlb4ZVHsKTdW+bx288coCHwTIvVvMaMlmLSh\n",
              "8+5IPLU9oM290jD1yK50LqFiJ9Mb6wCqkAO0HIvGh01wbs0KT3ZBF63iSPssYrxI1MN+A6bYicHE\n",
              "e6vub3tDR6vLQsctdP0mJnU0VOifGeYTa+a3zpwdnDusQMw2YlfvSbSd8KWV1gcu1cBbd/GQxfpY\n",
              "+EXlNu9Og4k1fHU3TsZJ93yBdnGbrEPyhTC3gV6mM/nouEmfoBKs7qqpiiKzqjX+F+4cK8587Q6C\n",
              "2vIGrDY87VlNjyynpkIWa9bXLJtDkrMNrbi6tUBPPVpl/tFKUmiiqEk3IAmpd+1X/F6RtTyyw5RQ\n",
              "7jeQ6d1CxbTz7dzzOsjPNJEFe0+HzofDtlgX/rO3K8u1U0hDxbyckawIWLRXOTqMC8WHYR7oF4ru\n",
              "nBW3bsZ1xRHwGlfhIBLtamI+BEGLMLegUMIAH3Hj/FDjUb2WtWvgEVAXjEwVz7ZnASOizhmVWlx6\n",
              "Zf91GXpY1Vo5lt4cdj0QvSmw68URdOOOGSXHviQ3M62KPlLS+rAKJiVRaIO/6nNblUrxz0Y164X8\n",
              "ctTrgoFnF7wP4zN6iItt/HrcRuxlGNPX5U/vM5nHaAHaJ85OC3Mtp76QRzIClxt7Nd6UbnYwi5LK\n",
              "472TFn+5/KyGCSCmfw3zS376VeXZ28Nzwlx/+nbP6T/pVamZxDTvlyJjuNQZ+80LrmGrCqShobhJ\n",
              "wQQm2xAapB5LgkRlYQUB5A9w522PqOSOIZv5JinY9DwWUmnH+SxTYqYoT5DmZeJNo02k3r+7hUH7\n",
              "xJ5ZeVfIbbJa5eS//gZ88Yht8r0QTi3P5vHlTaiEmX1Q51QNR9fbUTuMobrdrliDm1Q/TCLzkvNq\n",
              "0t1pSb4gDR27WPBz3rGgzCSmtiZZlZ1ErGjCuXQ6Wt0Az/fRRK7CSjkx/YvuRtYuMD+rV/aFJbke\n",
              "pv8VZ9qCoI0B7XiaRxwEnB6uj125RB5CZlsIXiIOR6IT56TnMf1apgTo8a71RwyxBhsHfiSoVV/u\n",
              "R3Ic1uXbsysTSYIVaoyUZ1saEke3rw89Qtgjj8aNNy9SBHgOJ89zZCfiwl1/BUyWnBGU80X5Ynis\n",
              "R9C0T5HdJd8IiXVXEPex6zabeYtSnSJtKwaMVA34V5VUDnbSf+ZMeEIsKQQSIyeg6DF09Akhr8P1\n",
              "IDgKo+d/aLnlUatSr0DX4xG5R0gaC9E11jkkDDjQBihDv0JCAAA27pL5VOOtY2P50V8l679/RpO3\n",
              "qcAVyDal6Rn3akq2Rae9M8bTbJfoluWU+1BDmYT+wjg+Ru4Xg1pq5PIY2Tf1sgjrtBVzILLL6N95\n",
              "M0BEKcwgYUztVkHc34J05Jg1tIGYrarXf8eoWiCRjML8C+ELgW5ob6M5kS4mKC14ei4sB7uSIhgj\n",
              "itm0VaAXFL/Pz8I6qsxoo3/OwTFHi798BXzxZo4S9injc5Xy+YmPL+fQEXsZYRRpKxRADM746lwq\n",
              "5FKyl1dZMsFE0cnVUrCO82DIDnilxGZqHykpw3TecE9ytTid5u/K7p/Khps3m0alQO6bzbf+hERX\n",
              "zvW/WJCTe5S9ijbrRrNTzi4oJIOectAkFR6Q9rtRyuq3AsjaI0zLDkCF09ubOYk+NomNshOyWULJ\n",
              "7AZmxT3HbuP9It5zExaFDXyO/WZ1/VYZKL3P+BMf7c+KsiSnPwy2m/sho+0YBIVBBD4mbFoONVAB\n",
              "nihnH2gWBpSsXw0pFJOkicJeRuYWj+qSEyDoDOyK2T4eSl7ig524Aqy0TyqlpNiSmrodoAHuv66t\n",
              "YWAcWkFuFWgKv0qmB6lz7mXQdnsMuBTUpCT/pKe49LfdtflMEFjczD2X/TqknPfItLv++Ulev7e8\n",
              "UF7dp6GsML61QxDkrhS8FAjLR6CjbRTTy/tdKNpoho5mH/lXzWqrHiaigKnGNMqyU25dHNGSI5u2\n",
              "9zzdk+QnY/BRFOQoTlnF23uly30cfpiJ8z78hAEeyfJu3a2r4pmrmMBhPZbfIhgFEzto3V/uIkad\n",
              "kpt2LR414MUwSEDGS4Ter8ErkH3+AjdGU+dJA9ys63QOdVSr+eo2VP3IFbMzhL2SgwY+YAP61ZJw\n",
              "sQtPz7fZ6d2Fwydbf0fINsjF5IfATXDsNDMdho0A2EDpccCv6zc7UeVencBbDovKHha2bgcXgV/N\n",
              "eVxDxEgaxLXcbOs/oi0FTJAQT7pGf25WGN8yYDtc6MVSWHJDNCsLPw1dfgNPHFgbG/TufhKpG84A\n",
              "PJbnyrkbdmfD9CBqNRfQPODeFfhyamfH6ObmIaUCjZIoeiUaHzPXfasdrm81wM/YWUEJ6bKDK32S\n",
              "812lpvzR5kOizRod43L7/rumpRwRyGcYG9EUD02ovQQf+KDB3B9wUPJmVNiZ1FLehlNYboH8KATQ\n",
              "vgksaQVKgbJjrt9UqXrvA2z1M7/fxCqtQqkVPfmQ+0Cud43tPVuar7V4nZwZd7/sqOWN84uWTGtZ\n",
              "CZLECZI764elOrqOp9fkePkOS2M1pHKlFwTydUpMd5MkRFp4XSLAaSB8I/XQRf4ZOidTdBhllP1R\n",
              "Gjmbs0Gm3JokpwKgfWSlk+SoxVd/TuCsj5VZFsMWmQx+KHTWq+7yv7d1+HoaIb/VTfwdJ8rkuMfU\n",
              "xFzuyOWgXug0FuOvHJSoensGs1LcOUErBjSdIgvqDqEDpWji0qehZ0k98q9FLz/ipG3NQy+5+zjh\n",
              "Ms30qXCUaJiYddY4fGTxtBfuDer40iYTcyCnBNqIqRSbNyUPc2DZ/olHFUVg92bxwC3ssN3gVKni\n",
              "h7fBkKPncsN1JH2azaTp6/7nudL7P80gbeS87X4jgVwc+hi3GLQGPWQi6HNn0JBUQrPrUL05uwfE\n",
              "4s8beT2Iv0KSMYGZVyb6js91nrmozPEbOr+AFI8xobCXLoVsX7VvqJKJsx6/MFxmIGskySFBcDyf\n",
              "WYc4WTGxgSZe0KdhXk64NLB+lYCCL4JgZvIhKYijIEHXFsNf0D/TnLl7jgB2Xt6YN32QhJC1hI9A\n",
              "W74N7PnVxkTp8AJ1ft/0sAN0RANiTRlWrIuEpTRNs9GFlNNuDsA07K9E3nsZXZ3NYuPj6n6aol6J\n",
              "H1eK0B+aMje/FlnzFn9UvZmwQ+9slaZMCwPIsR+VoYRggAP948TxIQN+Ehs15VeoE516qSgDSZo1\n",
              "CxRWZmj9KuszE0p+ZcbfPqRHb05PuVWNbADUjKQmUyGqpKzflYplGeni5ururoAvux8pDNoZ5Sgz\n",
              "H5uOs5myCdKpUlvjprMoK2bbkh5cnsF1FWkfc9lhk1Pbb3kqOIMrUPk6vtFHuP+HhdxV6P2LcuLS\n",
              "BChYXfTOvOFqybFLCGFNBYc77ocaJ0V5fTBvqpsGLmBNGpmAsbrCqlj6AAF9788wVYrepNHweAJC\n",
              "Yr29s6r4TM3utM7eYUxJatTKat6eYx3KlLYEKtO2P3YgCCdpsayg1ILvZXSyp+uk63uliWfABCoH\n",
              "dyDRyUZh4AMjPPaaq//XX6ELKIRGaj42Bc5xKpTC+1gzQLMep8z9ppFqyZaVS5x10c2karpsPBQ3\n",
              "/5hcRXOQ452VvgjiKR9Ic5D3ZtajkUl79QAWjfDxHFRcb3nNaKy4JTDFeK1vVBgz7WBK+SPvd02b\n",
              "NBQVCrTbX90/7GoiY9SSpOp4qrVvEagq+nAvqzHOLTXYsjHTlqw+6Gqi6sVD3vCMzwHkDCDzKqqH\n",
              "VOZtH2v7i3hi4AhJ9tpjlYxt5A31C/lb1Sl4s9xvcBU7JwyFhO6TmCHSO746QjrVSyAJ3XsLAPRI\n",
              "joNlYGTMxosf9/kSt2dUujujRsJeQ7dcEoRAbw2411mcdoENSRGASFLL6KBEWS+D5R+SGfrGExre\n",
              "QaSwBDdtobL5874sXd4kuA8P1g6rio7vPJCNYlmYOzrvsC318MrawjBe7vNnTVoOS1PO6RMrz2sH\n",
              "gYVom3dx//jbKDRa6XLmHmyeQg41PSGGG3lTW12xh1hl1wfugE/F6S5uZ616ynNZpwRkpunHgmEb\n",
              "bTfPPgidoK4GniFBPJzp5XZk7/NEXfsgbYgLNHImIIS14RypYmtEn+c+OfRJvoKKO6C20dDvBrKe\n",
              "Sbo0MlBTRxe7j2+Jt4r7X4nrWi4YoZPoiRrf34dQR0tGf0erjM+M06Kcxn/8jpppyN71MKfM6949\n",
              "0GYKUkbiV6AN4c1DFCM3m77EA76B1QE1EK418Mi01C07qpIt7spTolQTq3X/ofRLm01oxdQs2l4x\n",
              "3jgU23mPTvSWjgaiSlnlRDsK8VuNXg2skupX+A1S7BbmpFQhPhWTPA662akUs+gJkKHD0dkXy8cM\n",
              "QIAGnpEjKBifPuo+CZ5+MYhZ8HVbR7LEK3m5QxIpd8ijPeT45DLi9yDO4Xdb0J+IhZEqzgj4n8aY\n",
              "hWenVaaleexumtw+fUO0JKaAVIa8JPEgt8ccRJFrMo+R2fjzEMnfQchg6tsvwbxybtG/hsoLAtLd\n",
              "NYQ+xnun7ArLodCQQGnDNLAapWq5sRpmOUxUTucOVntdrFWymgn1I2znd3WZGQ1BIuGOn/OPgm1P\n",
              "t71V9yVtp9YWgIRCokbLp+JAML6/VluLVviVFl5NMxS23blWARYhU5Wd3m8gNPu354Y3UPHgodII\n",
              "MJ7UoiVPIalUTOvkuLZeaDyeYbOasjmzfDuqrKSDqm2ovHS3z9lkZlKL8mv8PChd0c+/MyRG1psS\n",
              "JPY1iuf8tBZuUXCDw65UJEjaRLTqKJeAOYviuz7+orQQeF1R0nKg+fBrE/scCKbkYf961d+QCzl5\n",
              "1F8pt1KHdOm3FeJ9KpqnfKdwQkJZgt/Q3QjEc30cSbeULkyW/CrQYS3PhElqy+g+wKyj8QgUh5rH\n",
              "CRn7KEk5NC22StkDDaNIFLdaYlavPv3ztkgtQFXL+uTQN3MaoV0rnfTuMnPbyOSvBilaZf+Y9Fyk\n",
              "oWZJDGERNKLaHj4kZzH3ZLrBJt4pxNsBr+IDd2aWRxH6Zoy6fcv2GYPrKEWli4grALskoFoVO6zm\n",
              "zb8oFavMbsZgm/SeWfKhKSdR5hJyhAxxnMogNCkrGauena1tnNMmuO0s0orbGEJihZs7+gJiJMNV\n",
              "v1AhKRwZL3+JQ++ZrPpRUoJ0BzyUFSeK4eBsFPikxNIL9ygBpKJCbSvblAU0gh8/+7gR7ju9hTlz\n",
              "UQIyfKNzqPeNqUuX5eMpvpheipD1S0fa/JFTQoo/KFcHJuQvWnF3WBsY8I2gg1cXDsiBnYPTEy/+\n",
              "XnFeIxgeCkXpqmyY9+rrEKwcs2/YrvsiNeuSYh5R8VoDLtV/G8RQTbNSCeA4iCReyiT2jXY10IrZ\n",
              "bAKSmgd/WRBxj3KWTwsOFAM41kZHEYapAZMIFwjF7P8g83pOqyaiV+562p7gyft+TpyfY/FdwjAd\n",
              "NrRB/Y9Q1tMO+QBZ8JbrjzcPtz1N8I4EiMPUIpszQtKpmZ+TZCQYYUMaEAoW+Yy9UmK1eMwdxYV1\n",
              "jYFKOCDqQbIZGCx1NPoMYVXaApQ/CoS3kKUAWU+BAsabT1v8/h5b4fSs/QEFMXspx3PjZuBi190T\n",
              "u+dowHI5cLlb3kETyQK35y1r0y17TD86x9pntl0B/LW1WZQwarR69PdQAspuiiUxuJUrgEcWUO9D\n",
              "49qqVUh86KvDRHUrN6YhUDQrlrXZKRnPnmLEqX6P95ZtpOEuhId6qF6jLyhbm7/NWnmvHLzjwsTV\n",
              "8f07ZoQclryXSXNaQjZYbsAiC4PAo+MtbH+mjCohVmngFLdgZp5ZPRhge4P38IP5mFPuGgaFhv3I\n",
              "N3j5UE7Fqb2xDJIbogxDVqT/x90l5X/7VsHMvB/R5bfGHK0UxJaDy4w869GY+dQz1V++YAZxN4ij\n",
              "2mIAuvGFefKulrxHB+PcY4AfuTC4o33ZrQ3He/OUvL119L07pbT4v0n0M4uSrJqzMf2B7BAYhRa2\n",
              "sUnxaF1Yo9eyOP4eR9Bj7htDBORLkgKkMMKh2C1zP+yiBzUXbISh50XdRmNcNkVpTLGOjy5cAG2z\n",
              "j39xT6o0o7Md8GwrUWl3dZkkmxtZfyfzb17XaFs7fndVvmzDZgUK/al1RNIHkKumLnCu+SYgCs49\n",
              "xC1AGss209C509B1C5SuCwCxdpgBA/HnqmGISi1J6PPkZxAyYwPQMSra1TZSsbxJvv0OgIA7IMOw\n",
              "Y1c9xlywPKkBN6bDwKNT6xOfKJggFLlNRioZKXFXez4UPfoaHKNn6X0XaW+rowi+eDz4CpulvbV8\n",
              "mOlnvNv8II/MHQ13C5ZjOTbylIs7a606dAFSg3+ZhWOgdUIbaTfEVbvmue2clClrLHLP+QXwWB3E\n",
              "mkfRQ/sJPrs8kdZijltaivtAzi9rHcR3Rlt9lNXE20Irw3M3/5eUnL8dHxmAEySqNY0/RmmGqWXu\n",
              "2VTAeigJgkx4b7560mm47tzV8MMkSHDTi3QeUiBa9sHIBa94rPh74YHXZoWVmVKvFzWz03xoP9Cl\n",
              "gGUsjAjfVHlf21V+2YFJ3zIQedLFKB4rE9blanT3Zn3XfwWqjpLME5OaA0QYytdWbBOlqvsOsmNN\n",
              "psYxxBFpEIzJEwYzGarq0CaOUY9k1XRDHF8wtU4q91bv3nc4reMI5EcRElUvVzibXfhg5Rx0IXBf\n",
              "cJoHFhsRJWV5iCX6sprqokY2A6McemawBLDXQTvGm1g8c6Q1Km7I5x8PzjkUHcp65XaA4uQQMlSQ\n",
              "R3Ei74rmG11M5QEz2fMuJ731Egg4dPhveGsNWQJHkCT2t68FA0DpUqSJk2xy3D2DjUfG7UTSNK9R\n",
              "WybD81dP8BB5WxUnkzlOAcdu1ENYmb4HAS4zrHK8xrmPrfKfOmvz8TG1/Z1zKb9Sd9zi+J+AUC2j\n",
              "RvIlfdJnAfDCd/5Qt6BelzeR+dsFt0gxv7xIMDj30mEh6J//D1wxC8EEmyxw13aREMpQwVzdjPgh\n",
              "RinDC84NjkkUdiYqBfAoe4j0H9awpqafrZxa0jOeyDDfwDcEcyhgp6U1cQKn2BIDdfLtJgS0+E8s\n",
              "9HSs5jf0dLERNJK1ANSVs2Kd6lrzfp/dMuDz2BbkrLA4pda9fh9hgWLpk0v9A2m6guAmKWsyCuLP\n",
              "P9mfa1uijpDVP4TE3CiGWoSApODCPfQXCrtpi58+ktoGg94O3zPARkEwdgGbXHyZhjeBoUEuXtcv\n",
              "B7uuyTswRwi93UnjQOM99sPzCD23YAAAAtVBmkU8IZMphD///qmWAA1XulWYhmDeAFl6tGu/RX7k\n",
              "2JcsCTXmJALl0+QfIINYz+vZRbHnKxtthagGN5TZI1inGfuOivx4qyViyUxadmArDAQGe4l1eIMV\n",
              "/Y8RthpQ81urX5wpEJPaUzawxF1PZkUSlx9chpxoyRDXoCKrVh0Uv9r6Mn4iPk8X1IAPcUWT2Kjh\n",
              "iVCcjwZaj/vCrc3vEmCT0jvpkbFTVhubVmSiR25b3M9XSypJ17cj7iysxfp/LVZNrjkF9fIJkw0K\n",
              "B0HVI24hKD0F/XkcdSOXldlv6OCiyiDghWWgFhYmpZ4mBjuppivtA6dUAH2zs0FPZXlo80nOIf9R\n",
              "DY/zm/EWpBKYkptAAZAPw9MxLV1KGN0mk9gcgiMsGbBA6DB+1nntDvbICwNOkk90TRXPlYKRiB8V\n",
              "tH/5zONe80TiAcuSYUqaEwa7eUELE/AmLTFc4ORLJ5t0lWWL25g8cdt5Mp93kHDwtA6R/L3BYxWn\n",
              "HkgiG7ArBRg3KG0nckPGBZKK4BL1oF84qSA42SBKhkQ3Uc71HN2CiYO3ETaic79rZHQJS4n6B6wl\n",
              "W9cRfUWHIVVr4Y/rXXP/M7zbvMz+DFFHXnus0hhXQdegFqQdtnbo0xlc63PxknX01r40oB2kXbtS\n",
              "jB3zt8aRn9AN/MWZaFNg7o0NVfJttWi5i03OoelptyTMfsj1szMAz3msU+DNRpySNftHwwwNz9G8\n",
              "vrdEe/R56KLaDsa3EkrVIJVYTFo2pgNxIwCu+oUgUm5X0ai1w1DV3Oy+7eOvy/eMAxgCmlHZsHgp\n",
              "p6HVu/MjLkDOR9/ezQ/1b2ABOpqE8P+3N4QU6tHaAvRS0zaQ9aRtyW3uXPxOEWFoabytryWU5ZFR\n",
              "huipdcGvz93UbcKb9oc49EdUdTyNADBeWY+N0UHi2kLI/rUH2bW438xM26Jp3UeBOXbn5zoqomRC\n",
              "9B3eydTFOJEHTQAAAS5BnmNqU8M/ABjeI6aw3Fa3gCKyRqgXp2KYZM9T7XZ8Sgr3snKzEF0dyL/4\n",
              "fj4KufpJN+l01irLM53e0gtuhqO1sWbK2RwejjAv67CDQ1hY6vnYrVTl4hME/FTtavmSch2uEZTR\n",
              "yQUsH0qGCgj1/jwP2Kr6nrh40g1xOR7VEkRruyWX+VCON1e7HXtcqO8/1nzVr/cjjRNeSBXSWx4t\n",
              "lsv6uEkV+yxNxi59gqCmo8f21N/xLkt6F0Pa1UdHhVaFsRa1QusU8W1h9FWyfFLrWc5FhO3oGTWX\n",
              "9KEf1ZJx0dLI/Vm+y2ULLEGHsdMDilbzH59YjCrLASfFGy72wfckDcHreR2WBgZpTQW+e2BnVyr2\n",
              "/xVOw5amPgwEgS7iJVU8G+XiK6SWQnzBdAUdck5KwgAAALQBnoJ0Qr8ALomIxpZwOYACC5RaY1Ez\n",
              "EmZlFMidTNc/gp6vuvMd3yaFvI4HCxewu0WEEDZIPI2WoQWDOj9Zil2HphBlvjSXlAI1u4zDVkUm\n",
              "T05jO0FG8xbEP86kHUBHfMTPD9QEa0gv2dXt/Uom3AwVNX8VFjv9AkM6PF5daVyCsIBp6w0JvYZn\n",
              "+SwfgviAHVjLI8KZiNnZcY7MKv71v1xsvRqUjEexWFj4tNBklgzmqLT2LscAAAC7AZ6EakK/AC6W\n",
              "AK1uxwAFz+W6TVVwNVxBqaYcpKMhBRJt6/8C9A9Tbig2RwLTY8W4jFl6QjLZMGs5CAw9Ox8Gup4h\n",
              "5gbZJbCPS1IzGoJWz6v11JzV8JLGMsVyUSHNVgefCue51BzrX7CCPYF99Di2UuS5sF3coYupTPZR\n",
              "6Z+lisFh81JQ1nAbCq7UBpkdvsZouQfCGHv5DswC2ZPvkWvJJ+Fo5n4GqEH+4Tz4CG3+s4cOoMLX\n",
              "/mQNhmowYQAAAnZBmolJqEFomUwIf//+qZYAClCtjZyUAG9bd1hWkA2oKAmEwLmL1jjUZstpJqfn\n",
              "lcjXmhjrIA3VRmluhbw1b8RBQMlLfRRZco+7Bn7bLPsFHs7X5IvChpaDxQAZKlbJ8OMGMooFXUFa\n",
              "3BpmBnwu7JINOVqQGtGdSCbo5AN82ot1nCy4VFi9dv/SenJgnm3S2n36Vy+1D7B75e63Zp/J6BFp\n",
              "CJyvj20vEsguZevmfZtaO2wf+0MCsLxhJKNVpu/QDo0X5Fb51xf0qQEk8Kc1I0wzLsSBk9+mxOMh\n",
              "1r9jHDFv0tmirz4/x+tn7geKYFqxpehlwABX5Qa1wtp1Zgxyr6lehxmbJ5U0ImQ9aKpRp4nrCwKw\n",
              "61Ldb80Up0ejA3zjwYqdCmO2D5QETODvR6Z9ZoCgCgRJih8AVKLS8pCTX/wlCq5ThIclA5y5OoPX\n",
              "k+zSwevhlaFJ8Ci8/51HXv6G/giXEaNMJh2igI/ohg2jDtEEYwSiAG4yIV3b3o9CsmXY+1q48pO2\n",
              "a/OzKURkwT6nbIQHG1zaQkQcwERZ7kQOL3ybEDggWfpZ18GfN9hJfTuK5GqXgYIY7O3c3jSz5yNt\n",
              "Hb54YfmEUV71qfaPlwu/3ohOchWIBb5mwZhlbqJgjq9BYrE58fjjV7OeS3HHVzw5zZkvAvBYAtKO\n",
              "jWsQbqbAKbgRX2ftCNXBs7i2KyczSdZBm3BCJp7VliosfZdppXfb501M3asizKEiPQbRxrfc2lvL\n",
              "X/n18bBY0fE6PaFe/+H0U3Z8qzkYdwYXmuw7ylbz399aTaO16ftijJ7ipxP0oLYm/m+7+mWRr5oj\n",
              "z61DR4ZlkP0ZqJ2kQVEAAADEQZ6nRREsM/8AGSYcrslNAELyZ+kfHDln8TCKa2wiqtviHF19irhv\n",
              "jIy0apeBR3znapjjCeM5fpAFykMxxSF5pWBW1mzIwjHLd8wjETmNUQbLeAyL0d+9Kah9o3F62UMP\n",
              "vCLAhQzLTZu46GFPQCYaCpRemf34O8oUzDvXv/L3dkT6dycQl3F0rmyJXeccU/DRA0BhgO08aPiz\n",
              "sT0ZllM+seEuhh7/5z524GJOVluvIqXOAmXgbs2pgOQjV/TwFzz3Gq4LHQAAAKUBnsZ0Qr8ALomI\n",
              "LSmLWMjceOCakXxpwT6jSMYgBb/xkFwCAvWebCwj6GJQu8pKzPxouf9o4HnkMVNNZyOj9KuAbMhW\n",
              "M88FHiD5JP16gt1yL1derYh3UEU9V7bAHfhzQYcxGT4EsgyWRpz2tU0K/h0EmZS05v3gLCkqbHr5\n",
              "4EGCdOkOYZxEdehMA7jYJ8djHQWwhDWDuxB9Rz2lo/DcsheTMCcn0kAAAABuAZ7IakK/AC6WALpl\n",
              "IALDvI74xByn/7CMqgmq9c54IOSsiOYm0gfKGB+DmtGh9zep8mS4Zay+ovn7OZDYKDW7CKtVlMdE\n",
              "2RHUQ6zBhZ9elm761/0ElQDAUVKnDfwfDDqqmM42ADHR2sDU4BGeSWQAAAGEQZrNSahBbJlMCH//\n",
              "/qmWAApfwyP5m/w4/zAOoux+4/ZkMmekYteCSG2pTM0uGjBKjnzselR9kbQfiurEzGcEdG1t2HKG\n",
              "v7QCUWVkZbTue+227GhLfe/pNs9h62Hlxidh0XzU2AVY/ihEOU8m7pI9xQxdyc0r7g0msTnxrSTr\n",
              "abKc37yF+5lKcaYcux1h3lk+KqPSuKr+LzOQ+275sRxVaq7q4dtiolMri9koO2jt+9pjuowbgo3Q\n",
              "9RFBRP3VNcoIgUQ2t7Gjy/MCwY0tRm+rkt9T97zSrVI07C7NL17lB6YLZyngiF9n/5rxCj5PuQoU\n",
              "zKY1FTRPKc2Zo2ULQibP5rnTDoLCaqE9rib9u2ljodZfTq8Vtu8S6Rb7TCrOfnQE/xam1QxvV/34\n",
              "ZP6klN8qhM12f78W0nak3Vwv3Fjwxg7OQ5Z+jfOo1PYUWtSDvCMDKB7TDMuybNoG1KyrkVXsHYDi\n",
              "1qkWCyeObJ0PN8of+rcJio7YsOR4f4iZuGj7VbCNc9cleQAAAMJBnutFFSwz/wAZJhyuts1QGwAV\n",
              "ouSZ8QFZ+nG6dV32oCmoz39WQTPVtvkDA9LLME5We3bRlJfTDt3klaV7uLxV5cS09yOB2LlKKu6e\n",
              "CJmrt8ePJV4r9bR8mBwW/Gh74Y7kcKS1QJZYEpqdAN3dfRCis/y0GvJZnjiK+SYoqDrKnXxaiRgl\n",
              "ONbLBMmD9cwmATEX0C+218tiU80gFzPPS0oHEPblaAlhrW/DnHLI2lAVSwCUFEW8GIn8pVZPGfa8\n",
              "Po+9NwAAAGMBnwp0Qr8ALomIOFZSmqAHSGvoy7b2Auz/Bz9Y0lvoqO/v1i0Fu5eIfQDcf1FH8CDV\n",
              "YQEElHHgD4kIco23uDPVog0VgnwYvAxdc6IA5N2UMbwzV5Mizo1kc5thbfYRLUnnksAAAACgAZ8M\n",
              "akK/AC6WALjPRtYHa9HoAbkqVikHKx0OyfAg6V8H5IpqzKqwrBzUrHTtlMOXme0E7xQrymgnAeNh\n",
              "RoYNjf1xlFYEwKieWGUp1odpxemPMsFGULoFhqzBzi0qe6hiQFKr3TnKcVdUaoAQWicNwzJQbqP9\n",
              "OzX0bBjI7ebFbsSdeoCRywWUXdbTeAxCPGgSq4Bqn4DQgoCq/PBfXP92qwAAAp9BmxFJqEFsmUwI\n",
              "f//+qZYAChfCuHe8TZ2RoALaNzIcEVwDBcb9Oy45H3VJQmWmIYx6MbZvW9tVANHp0vtLeRoVqna5\n",
              "AH9csbMkY334OTM+2Xa7q6PN6M5NedmzlLWLlpc5bafG9Qz/z8x8iJB94kbf0XMvP06tup37x9t4\n",
              "rruHkRfst32gz35Jb+SaMzhX0GRMFRYf1x6Mex/WKbu/btnaJU2JZmETCzF2omLe/BWg+PQe2CuH\n",
              "X6bANYE0DjDPE6ldbRs8hnoU/plDkGa9iFRfGQvyIWZgKw7BGfnM2xAhOWTK1gbulk0Jo0yT6VBD\n",
              "aVdUXd5Soi/Ysio4fU6jBoXjszsoOv+gT1+kqjiR1NhI/mYX95PAXb0474PnTapzkEtW2YaUAas7\n",
              "+Xm58DgbgsykTCfTPTI0rw139ufaBBCTKG0KVWpaS0LDkyAEs1oFTrRpV7UcM59VTxxF7l5OFk9Y\n",
              "Wdvhbvfw2q9knyqMyylRGQk1qjLz1H4zofsfyQx+g0fHsPi9hKuHWkhcS6Bk43Awirk6c3xRCm7d\n",
              "UOMNJHPg9M9NnyT0vOase5gK2eADzEiqNLgnFm/GHp9PC2imhdRHBZEWWKGNJdu1eXJzUmjNTzRY\n",
              "azirwRIHQSnYe2AhmCjuYKmO2Zhio4/A41qG3oPrqgzw2+BC+ZN74v34UwE1DkCTPMtFIriC8IYz\n",
              "4TtOosxULOG13fzfuZjlgiLqzn6ICdGarQcu5PdsdzyZhFqVzb/s/DljAJxi4Ev0sLpydDCUvYeP\n",
              "DPRfxlFV/HprKFWhedK7Y61VUCBINnF9qUfld34GfiaO/miFUY+EHuVNoz1IPlailsimm3mNC51i\n",
              "2Lh+VyIMtBKxMUHMpL7qEZizXAwV7mZ60nIyEl3/768PlQAAAYZBny9FFSwz/wAZJhythsyCaFJp\n",
              "ACSF3/UoDx9U1nQ6a4bMPAgq34LBysEzZqEZjaX25jKB5bgiup9Q+FMuiKgZweWBOZYVbJBYGTT0\n",
              "7j6YoiJvTwf5M/inbbpepFk50L54SZYai7VqOsWnJ8NsQoVpQimU75QXvuHBaCUP4hY6K4H4Wsyq\n",
              "3G9FlfFmc2iEHDVHeRPeTOlpL/2AemO/LDnQsxto24lLjZDsxGfkWOgWll1J/W7XZ49p4BV0rI/0\n",
              "foKL9nnMWt8kxpxfs3qSfNvWlA3xfYivNyhql4xqBWRZoE8MQuc/fuQAnaXCxX2ma9HGFABRQWK6\n",
              "1UN6cH+1wbnACMdfn03Up1xsq/uTm4Brxn4HjCA+H3OtgPTVlH5nsa6R5Z1CxC5lJ4gqjja7YrFk\n",
              "UzwClJvWxIuSRps6yiQgoZ3FJwCBSYvWmNYReGG1ypyP/tPCa9ZZ+/YSUOQzPpXyhMD1McaLS3OG\n",
              "WFwqNEQJPVRM7Wabc6w/y24fvJWu/gng7QcBeYEAAADPAZ9OdEK/AC6JiC56SFsrYRG9IzRaZeAA\n",
              "cAQvhIjaj5D7f5pzi73d+dlvEYykLtzmQJltNPCdx3zo7USwWxz6xAQG2zx7g5SlBMAmS9M+Zoqb\n",
              "vW8lLci1e9woe9v+SE2rX37wVZri5ICCDqkLn4NuCZL8qOwdv4XXdG2bWOIj50VvWnQSVUHbZh1I\n",
              "5Lvb0unZVPRPisdtdmCuA0UQWQ3hXAAtuCu3Jg1j+H+9y5LgS0HfNP5tProZ/NHeNBBc/70KRTiM\n",
              "TaV+zHudlaSOxwoIAAAAogGfUGpCvwAulgCt06PtAEbJz7AANLVqFRXxl4HYvN6MMqK3JQtnlk1e\n",
              "ziSMgrvm4vG5mDhqjw1P8n9P64f4lwAyd2iG8xGDZ/zI+qXT3M5WU80RvfCrmN/7rjqpqtz71LH2\n",
              "mdOUVHzu8ce1Z6XqLSGi6BW4cOXZeO9ga4HdNKjn2FT8qvJrC699QuDsm5k2ueMYB8F2C/EoxlTX\n",
              "PhX90olt+AAAAshBm1VJqEFsmUwIf//+qZYABQveEAT/+p8vQgTZFQTJQAmzEtWqcAXJnEQQSWhJ\n",
              "kXBUJdl4/lVW3p0C4NcKzjqX0F/aK87MI/udkIEehb4H4QWw5AR9Z4JnMeTyf7/ayqMQ1VuPh3xI\n",
              "/XrKF7kBKGniqd8J8pyFy/HyqVuf8wRyAibckgNmsQV+zONURSyJ3N759A1dFvzmL43ICh7XLm21\n",
              "qFYtcH0HL54osV4a+edXouwZcZ/NmJxNuRfJ/pHtlgEBB2Yx76vHFQAN3/QOUyWjqiN5Xesl3s+2\n",
              "BzxJKyVtIpuRv8iLbCWoqkW26Sj9r+nBUCUS0GocAedEJYRZa1bykft4c+0c2qNzz46pZvzwNTVH\n",
              "v0xzQfhgrycgibxY6terSxr3+rDvc4C9WbzV0uwqR3ZWc1jqjFhrNiJuFLeYAAckx/wUv/i0+c5b\n",
              "CTzuKsW4Kilf2Dl9IZ+fdcj0JkuSO+GXU+JtAmVKwqQDu5XR6q0gzI2FkfDV9O8xzmhxmyd1gBR1\n",
              "ncdwB0IeVexgCxlXVPgyvjGlKF4Z6C6Z6eRF5evOu+l6svk1jh8eVW0jryGn8aW2/5NFTNW9Hf8v\n",
              "mmT+tTFnEeq8S91wJMaDukVoUNvzxbKk3zcQGRcM8qII4FV1DbAsEhNhZWw+O8xlcvoMxahs0XqB\n",
              "3mF24E5RdYN0yYJg0/9Vfad3pmldtX/nTzAyJ8CHx0DaSacdQ3ev5UB/q/2pxGtx1WzqRBphh6ve\n",
              "OYf+ar6KH8Hr2+egb/2QKfirbq0QBjefyk+iwuiw7GR8m1CM5EpYazKcwLnOX7WXf4gPUmqXeky2\n",
              "WCz6PpxB/qzcmPJEPkQWCjFs7vblTeilwfknyvCbOf1fMqvH/kTg6VPSNokWCrVpAX6IM1j5a7Pl\n",
              "niwJotknR1ta32VPiMmu9awqFB0rCu4/0Csb6Nne0L8SMBircCuBAAABakGfc0UVLDP/ABkmHJiH\n",
              "EnMgFQBfnJKe/oIV/meduB6+8C4qCrev/RhjLgP42ZEyt5mCUzEs5ogPAjPN2PITHfAWcxEdEagq\n",
              "HpzCjhV1TNvPHf6nLZVCG8UvktY9RoVlEegm0mMKDcy2bwuu32H2fxV2qOmuvRcGffb9rcchNjfq\n",
              "ieLG7dKDSyS9RWAKbwnYpXQWjHtSPFuL3jKbFufK6avaC6m1p9xE+oE5EjY8Z+oTabRjhqJYAE1a\n",
              "0TymxDO1E8WD0B0qNr5Dy6jziExk/G3WTNzdISQEUYrRCd3tj3FhmITKmy1GxLst3N9CCjl6Lpf1\n",
              "6KKvuu8ZVo9DseOE3TwxDHoMYLcLaF8oyOy19B433t1Sp915Imv7b/waJpX7kiaOxQ6ad6e9t97k\n",
              "TCP0+NHeupEcvhAC66t1f7rbbAvNWdZr8sBeB8Bwy7AfLRKEv5RuCnWHvX957ElqESN65L6k87ds\n",
              "zl3U6j/AAAAAzgGfknRCvwAuiYdKOqJMzwBW9p9r2Io6SuuzuIbXeTDMhpK+2we5penuWdjTx91R\n",
              "I43G1odfaNgTAzs0hFfI7CndncQRHaxTGXkdgjLMR1mO6tgmOhvu4jgtVnhYw8d/4AFt8W/Gs5H3\n",
              "ZYioEgsResQPHQbOIg7Cj8HSp/ucLqdj+L2ah5YDXXpQiuXSWhfcG8U+O7HOZFUjqdRUQh5ot3SH\n",
              "pS1ilcrTRkfUVQlF3lzVNazV3vk8hNRAjYNU06NllQ3nkz7FR7Y0NqohtOBAAAAA8AGflGpCvwAu\n",
              "lf/KWtiEX5gzPKjBoAJUY5oaoS0/ZR6Zytq8x6OsNrAi66YgdCkM8u727qMO+tjr2nc68uh1rSjk\n",
              "Scl2ggDB4v2spjugM2hKcXkyoUL+kXeADzlqIDjLJgQDHd8iZLqWZ03FzHuXtcOWQYKPSXsEINyQ\n",
              "4uFW5vAq3B+Pu7qKgn+2vPq462ZyxctVDJdWyDuHinyRchTzhoGgif5b7YBoHoyiPe5ZkyKn7hPK\n",
              "SbraVc2n2vKn4eoqmC+we0I1W+fjcX+AohVYkDPVsyYQvvt2FK+ykJULz1IbXR74upu93A6462Bh\n",
              "l1bIEQAAAv1Bm5lJqEFsmUwIf//+qZYAAoXwyA1oVZjwJod6tYqOPLA1pn9jfmm/xDexJlQx0RSq\n",
              "udj31rMjuEs8VQPelGanya33fnpDtBsMIi0JTM7JaWkvf8QSBvRT721c/xg4uhqO0t/MfwJw1WKN\n",
              "f+sgSs9+WBKUaChHouU9EBX8jk0FUu/4zNCGER2ZmwxJMHH6WQvZVUJNd1yBrL4aVenH5BZsz5Bj\n",
              "ZAvmnLtbzg+85nMLXaqQpOk2t1QWMQ5M7JEnO6/UTynzCy13ndXZnnLRJ9DTAfz06EUtjbP7AJJh\n",
              "b//EvC+/FQTit8vP6GHaCgKjQztdBNyi7JrBIAwJYf0TGDU8aoy/ku9L4ji0hQMWVZY7oJQqldwj\n",
              "H43t4ZBowkJj/7tdi1M+Nb6Te3Y/oT8/lIfjblMtHIFzEKmgTG2Jw3vFougGZEwUFdW75IrRTA3t\n",
              "5o8Brp9iL8JjN6WVBhkQkHpAZ01nS+HMXIVzktcZ0DQzcT2DQBgY9pP7qCIk3aMtSIg46ZRw08KE\n",
              "BJCRw8ysbzPYceeLZg0w/k5K7yNJ7x89Kvz7Ci0AdBaJ6HlnZRrVUZwc7+32xessQJf42EuZxscn\n",
              "DH1kl15469cU/+PHy8THejaee78f592bnUZqAA2yUXFngd+BtHMyWcn/3sH2re7DFM490xULu2ug\n",
              "FjV8WHxRneyLPA8i7pTa4PPoVjxCUMT8HCq1st2u/8hazDrywPVcf2yavb3yjdWDwNM5erpRxqLq\n",
              "HjeNh1Bba04enUF1F3QfnK6GJQwxy6B61BR/Jd3aDX3HejotLOthgROIgDHnYhQXqyYo+xlYDpNp\n",
              "R9iB3frsFNppTZTnhhL/+wsLf/6ukfuTKP8MIF2g65w8AtD/WzuYQjp7fhSTgff2NkZBY5p4qhKj\n",
              "iMBZdOE37AtY2Hv/wMQpKAE4OUKsOz0UtBWXWNf4GV2zXlk/cgUyuP77bjc0mhGnZu1crAWcXvq6\n",
              "kAP3xMf2ZjGGxsYmCYUTuSfBKxRRSc6kzQWX+td6q34AAAFrQZ+3RRUsM/8AGSYcjf1grYtia3bx\n",
              "8ANJOoUuKUgoBvbbn4GrkdkVi9DgJwN/iNzZuf1PO5wfMUEjUCQIBv19ozoG0qWnp6yPVN8xdFz7\n",
              "M/xRYrVMR+gXQ4dsJXVnk9wklgZgjD7I63kmcvmDS5ty0pjDbJzAnyiaXpINErUWPfBB/taf8ZFD\n",
              "DbVB2gF0gbYDlDDcxd4Ml31nzdAHlW5Bm07RHG7DAUKxu8RKSSOG6DtH4zvnPTwlmqkrjb4dqZbS\n",
              "sbHOJSmNNOUlX9fRtr+jC8bgHUBtHaSqNQ9IGBklvLQ+sijUxNX8Js/ykLavBLVNMGuLpbSgvKKF\n",
              "gXPYE1K5dG8J8vC1JTFG1PZZfSgyA1HKxBe2Do/QQeQpl/nEOyOmnuKnsQubV9Z7c1clT1lhEidc\n",
              "8LEanIcrB0CbHyZqYhA/MvrnONGa1KSdTDPlwY3AvnKyf3jQcTCYQM6ttLitelXFDIILnXn2/b4X\n",
              "AAAAxgGf1nRCvwAuiYbZInNk5hiVIpggAHEXb9tygZ5o4DxWbS9B3d+GHFyIr1y8dFHpHUbmgc8O\n",
              "xLHijsFVODahC0v/3leODo1a2s38s8qpr3HpblxrTunPp7KE0dqIjEgKn9nuR5guM+7Hfa430MeA\n",
              "V+C+20Yb/ba7nBbWQBm1HAsf+zgyA6ve87RwQFO9jTiVC8Poj4e2p08Pyw0gLmUf90dSk81IIGkg\n",
              "N0Tvwax5NxX5MJNtz/5yb5HbL91+q/zutoKyoaz8BQAAAMsBn9hqQr8ALpX/WTQKIE2Glp/RVGKr\n",
              "UyqsrVadaVhIO1e3CAFT0asT4Ti14aB7NvKW3MwhOrnSkkSoLRG1Zs+dNxQtXfI0srtskGk8vVD0\n",
              "T636Ih7NEpAZhubGQX6/X53C+SC5TzzZpIFKny+171qQ4p0SIc+fncWpfCtx1JnEutHrORIuEUb7\n",
              "mYG91Af7fA/5J1RgO0X3oXxo/w5CbivvA4Ii9DvJrtE2DzupTnnVDu5hx+Rhnlh8XVSBtSD2TO1r\n",
              "oCdc6W3qHzlIuAAAAnhBm91JqEFsmUwId//+qZYAAnPyO8DzCEjbDT7fSWxZSUsMqEJOBylTTCoi\n",
              "hXVb3aLhb06t0FhZJT2OxaKFLl3b6jpY7utpmZbrind0SuF1p7TUBNE2z8f6wTM7YO/2dENKdRll\n",
              "urfQe9fuU0UsuETNEBPemmyasjUHoN05dHmBmowGixVLV1Z4csNYji47Yq5umaiwrcwZALf26B18\n",
              "7AeBG8z6rbwwE1jEghWZXO7csJfxFOqEVmpdmsaL4w4VsQi5EYI04bfaNy4mK38mhZjre+NSuwW9\n",
              "8PdDqbhkIuFQurWSZBFC2Q1GDx7rYXVKluJ1w3FaPaYDPNaHegAxRY8FicKPTDSwOlhVLk4rrHtE\n",
              "N2btjh5v7kIQ31MDkyugkizxZWa8aOTiuuBKh18SIA5BnpuaUil2q6CL0Ud5PjvlVWomNaqrH/GL\n",
              "AiShSYq53u3O0wbeQtqfv479RXYl6iHoJOAGQl7PFJ+V6IVBnmT5nztEtno3LNSZufzyjNZuCbow\n",
              "Jukfe7h0Te7KipKOohfGrmNbcPfQAe30q7M1tA8VHZ6fNEmDha2KkziZwzk+NGSL2jk0zyzuwUeK\n",
              "hMpy9MT/zEfor4+K88RTqrW/dUMlygKlqW5utDNvKJpiYs8r3yRF0wNDTQvBNWK7qeQF7Rhq9SYH\n",
              "Vasrc3fGMlbBYG5+qTu8CLgZNtjpKfh0eLYzPFttd9e00FhMaUvRqAIgTGv2vpPmmAOYGOsFP98v\n",
              "nniviugiRbEmuVASDRnKJZNYfGcqj0CktX5svxRE5KQnS+8YB4fP8KbewrAHo0Bl8rJldek5ZCIw\n",
              "agzFFA877dmu6jnw/yiG9vQb3QAAAVJBn/tFFSwz/wAZJhyNnRlq2gergtaUEQER/AATtnFpuYF8\n",
              "8X2NBuIXN6wkjXj8kQF+bCve86zqVg00cnVKdQIwSxlDKpvFEriFeKIdymKe3w0+A0XHuaf8zK53\n",
              "BftjcceryLy4EcsODgod+GVy5I/xf+Lmb/EwYYkXbT/H0IXxIJn3s8hW0TZbOgBME3nxxcNZ+BJp\n",
              "yzJsZjFUY5VcGO4ypc6WY+58F1bPV1o25DStWaAd36U1nC5igeCU+7XPKDwAGGvvOM7vjZyeReai\n",
              "J8hlXI+cov69ulEGhVpVnV231TdxVKxIba1AK/xb62zIVx6USaUe24DYtsAio5RlD7mlQt0ndOZM\n",
              "hOOTxGSMH+3abxCQ+Dt2BXhYTtHgu5JNY+z4z5pa/HXr3YyOsBQu4BTDw+GPmH4Et/NfjP4lXaKx\n",
              "DBC5Qo9c+IEwh8Oad2d9R1eS4AAAANUBnhp0Qr8ALomG1YfFnOOsCm5PZZAoz8STQ43dgA9wLe2t\n",
              "PJ1DgoSYH4p57Le9OI9ZMG4Qz7J2B5wbTq4D/0rl3zXW8XPRgCu/RK8Df7Si7FBHBIbKk1WlvoAT\n",
              "hexTySSka0d4PwttCZtpBil9DUX8+c7plxsc0pH9iLDkjnkHtjYzib4YQgI0/j0HU56n697vn0B+\n",
              "67OK/juqsaM7vplGQXidQPZCg/Kflt3ZHcB4uyucRsSA1XsLQAYT+owH73d/8KtAscf/TRhxZf7/\n",
              "lvj78qtFNWEAAAC8AZ4cakK/AC6V/1Vz5Tzp/z9rVtzvLY7qxZHYuD6ACWuaX+5mGuBqPk8U9NWW\n",
              "eleGJJB94opLUzoiPYgmv1HtBLntq/OhtR90LWV/Yi25L89s5q6cgByf/A+RWnnYubrqxT7d0jNc\n",
              "vBt2V8Zdh9RQL0Yg89I4hoctyYfUB/JfrZwO9fdPZh+u5HaVI7X2hldfC2cbi2EMne/dB90sT4S6\n",
              "+QjT31GuII+hoKLvKTEZEWlZjkRImaGpcXEl5LkAAAJYQZoBSahBbJlMCHf//qmWAAJj8jtJQ9Az\n",
              "+VfAAM+DU31z08PgtZLxOrBGeBNPEyo2wFohohkrX8Rkp+aPjDsTOEZLMzlY+ACZUAXarRaxZN3u\n",
              "FQT0XH/8/S+s2bLGlRKh41vzDKFOqz760LqxgZ9cTNpYsXr960VY/Wxs5MJO4X7NKCh89bv8hsL9\n",
              "aQyAZUjh3n1cZUYRTSfv4ouQFoH46P8zqzRsj839jdTfqm+ACDmiszj3dVKZz3MgeCO2lux70XOM\n",
              "mgccm8Gb6FAMg8O6zUeZPGKlySYTPjLyAE/v/N9DqyvjFmoU7g4cBP1KrZ1O8euHI1bnNWAy7LLW\n",
              "LxvWhONqRlW7G5aO/lGRQ0L1JS044jbX8qthlH7PKyr7vruCo8pPBEJNKcuojvTcSNzIxEjMiq/S\n",
              "oQCHLAO6CBBJpYJaLdsYvpMw9SgVbtACR3bARiB8XUvNfqFQY8rAYJIcBs00oy27A1/8P6t2XqTe\n",
              "vqQrJFYr+mmcQkedoIPUiBidEZIdfV4xXEJc7GOcSuU5R5e6xbhVNdzfMKo276JZ9WTOJIHgCd7A\n",
              "j3BpLBtI2mYN1mSYl4aUJEbWWdkiTJa4y4dFiifll3fUfbJI+Y8wi8sDgxxoUUOmJ/Or7evUezRX\n",
              "CXoVC5BrcRWvTdqBXhusgkVOkjm7urgWwlaku5z2it62u+l95rTMrmVFnUSV4wOlaM3/E1Hu5c78\n",
              "JgCpTGBO+XGxcdjUsgsEnzWPkpGYdHQW+CBElKliPk3WxH6PTMVFVERj3n94vVJMeyAqTDOkWUls\n",
              "DWqEnhCwAAABJ0GeP0UVLDP/ABkmHI1VGrs07uWJ6cJXPzLwoAkwACVXbK3e+XJPpa8kjC3kDyAn\n",
              "rijL2S4kTXbofTs2LKu309ni2noW7JXcUIR4Ej4XzuH1j7Qa6QdwtKmtetBe/OUABkp2TLhRCMmg\n",
              "mXdc1yaA57aFq/BN+2k9AECotPJfnXGLhN2P0px6bFz5OC/8jJQ3RFGs/X1iHIWC6/H0Ls3ggpnM\n",
              "9Ep9lGzx0Hn0e4BXneSfVVaLTMdLBJbunCyOd8ApDE4qY+utHKrOr5/0gqecAtkKgqNh6pz7BkZg\n",
              "0WJQydG9s+Y+gDeZVlVbdURRlqJn3hCHmYn5gzunayVQJYB0amTaZieq2iBKttR+C03XHYa9WBeD\n",
              "jK+Sm27wlvwUSpPuxSsXDhRPVAgAAACMAZ5edEK/AC6JhtMH17og9Tz3mqPOby2SrYTUABdQ7DS8\n",
              "UxfsFhwDp9vYOEa+H6DOy8KkvJtG4whMPVYwdXsgox8xk38MdRfrvySprs6qLkA6BlK0ChtO+U9j\n",
              "FTTi98aLIFLyabXWaVkuLKvhaSAnfjOJ73Z3RG+mr6JnySKdTXPHfJTwlj6pUzE3aAcAAACkAZ5A\n",
              "akK/AC6V/08bubIzWcN9R/DV9fPmNNB/Ii/W4AsK01xmYh59OZfZbEeeprMAcUgiRVgHb1KtB5jm\n",
              "OJS7x9+cUZQZPjItL/pGQkr0InjvzuGwSy9HKrVra4QRXGFcbYHHwHLfVb7nPWBZWO9VXOm/i9xZ\n",
              "sOjXG/GdZ7UQ7rNb9MGEvEdpMXH76CcTBqqpkSict/9sL4RY1TGbTxPdriJEGoAAAAGWQZpFSahB\n",
              "bJlMCG///qeEAAJ+No0kALZP3Wb2yh/iVYZw+cbD9HfqagqjM3/uqfnsZIvz2xdcN3J3tBS6LQdf\n",
              "RgeUAOlz8EodsklnJDpjgQuDqOeWFt3cYMZT2chs9DpxAm7tR0kdqTw4rsw0oumIr3yPUNw//Kgs\n",
              "DTthbqRhMb6tjW+xU0V3xBx6buJNq+EDAUvDAg8qoTA5uh21j3IVp8R553nRML7VZ8rRy+9rIQXq\n",
              "OFK5qvF7GHdCoo+MuvjTEi3ZkszzSepsYWaEFaVTP7znmAsHAiRok8BUh/n+wX8ytLqahQCxZPR7\n",
              "U0uRh4nia7MJ2blNor8kPQkBzxWRXQXqsutnAiSpdGbTZTkMZdvDqIYSmGvt5im2szvCH+PByq7n\n",
              "4ACJOY4SbVjgRki/bfW8cAE0YSwk8ucSKt5IxwCf5xb1ud6cCUj0lbAnN6oCt0V1G6xeqJn4uGYe\n",
              "90TKf8WqOoxi95n/YWlKsrMJMuIYyQ9QYiIZ9/kfUBzx6j0Sf4v3yrim8eMzU0tiSo7eQi6C/XCR\n",
              "LwAAAMtBnmNFFSwz/wAZJhyNVRq7NO7dAqeDxg05zy3A7i+1qC3cQBdVNbpNl9QPhw0h60CmylXy\n",
              "oi0SbbbYWP/ZIchxmn7MJACsX72n1UiMAmTXmdJVOHjzRPeBZLii05qpkx2rfZRP67YaUoQSaMf2\n",
              "07ibJNihfxPw07eErkAGesac9QmNWuNdNgHkVGIVlPI8wTQkHaH4i/tXxgkENBuXcAztY9Uj0Ct5\n",
              "8B6vwdJqeX7mpsbRhIV8LbbstceE4xNq2m2yqEq5l0XuhK1AIAAAAHABnoJ0Qr8ALomG0/SLTy7l\n",
              "uhhur9KLCnBRYIgAVQ2wLsOmvbQCaLUnwLfuA6MpU+aTXWZU1JyjFitEIDrt5tI+ywBNHgIg9p5K\n",
              "zwmVmxACRUyrtBxghiM5BE3m2m+ZhZwZo6gFGx0eAimVSGCCMHRDAAAAjQGehGpCvwAulf9UG/4V\n",
              "R0wpECkZr+pW0ADoAaAAvQF5DPY76FA3dpOvv+KMWrwIUXIR5hQBwlg/EHsPaQU3976WZdEmT4US\n",
              "EdeDb7Qp2j+zs2MF9nV1mEWLlouE1GG8fAyNOD2RbIJcgzwJY0Ht0+3oOUn05LsjIw3GNTi3d4Ux\n",
              "HMkv4aq14ZjrefBZeQAAAJ9BmohJqEFsmUwIV//+OEAAEmWFSVYArXd0NPUVe3mZ5TdSvT4rqYMN\n",
              "5qJReyFFMNe7+z2O423iQNxGMt+vNQC9ysDm7DUCLq3NrVvqE4nrR38z9po2j7oHblEe2jUS50Nm\n",
              "btiqfq+HfkglofDKGdM/HsOGK5azkVn3MeTRgWNLHAXp+vST9gRcpRpM8JTtOQVNXXvDmS48UloH\n",
              "TKCWok0AAABwQZ6mRRUsL/8AIb5zGu1Z9WY6haiuNRHAfJiWNUqKZuAA/QsNi76+t662CZ1idgS3\n",
              "F9mUw93ry92P4ToqfZH+DMra80zOVH6Ihnpbw/f5lAHGvz6XfjfoxKo3RpfTQT4msDS3xkaDXdfk\n",
              "jkhOLGhpuQAAAFoBnsdqQr8ALpX/VBv+FUdSCOX56iwssM3QaCAAE7RgapeRRfJ8aeSRaM8hFe/F\n",
              "l+IQNEg22tXDwoSE4NLwzcMZp6xWiJ3v3YKFPdoQCwfqD/GrhbN7/dieWBAAAAUKbW9vdgAAAGxt\n",
              "dmhkAAAAAAAAAAAAAAAAAAAD6AAACAIAAQAAAQAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAB\n",
              "AAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgAABDR0cmFrAAAA\n",
              "XHRraGQAAAADAAAAAAAAAAAAAAABAAAAAAAACAIAAAAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAA\n",
              "AAAAAAABAAAAAAAAAAAAAAAAAABAAAAAAbAAAAEgAAAAAAAkZWR0cwAAABxlbHN0AAAAAAAAAAEA\n",
              "AAgCAAAEAAABAAAAAAOsbWRpYQAAACBtZGhkAAAAAAAAAAAAAAAAAAAoAAAAUgBVxAAAAAAALWhk\n",
              "bHIAAAAAAAAAAHZpZGUAAAAAAAAAAAAAAABWaWRlb0hhbmRsZXIAAAADV21pbmYAAAAUdm1oZAAA\n",
              "AAEAAAAAAAAAAAAAACRkaW5mAAAAHGRyZWYAAAAAAAAAAQAAAAx1cmwgAAAAAQAAAxdzdGJsAAAA\n",
              "s3N0c2QAAAAAAAAAAQAAAKNhdmMxAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAAAbABIABIAAAASAAA\n",
              "AAAAAAABAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGP//AAAAMWF2Y0MBZAAV/+EA\n",
              "GGdkABWs2UGwloQAAAMABAAAAwCgPFi2WAEABmjr48siwAAAABx1dWlka2hA8l8kT8W6OaUbzwMj\n",
              "8wAAAAAAAAAYc3R0cwAAAAAAAAABAAAAKQAAAgAAAAAUc3RzcwAAAAAAAAABAAAAAQAAAUhjdHRz\n",
              "AAAAAAAAACcAAAACAAAEAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAA\n",
              "AAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAA\n",
              "AAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAA\n",
              "AQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAAB\n",
              "AAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEA\n",
              "AAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAgAAAAAAgAAAgAAAAAcc3RzYwAAAAAAAAABAAAAAQAA\n",
              "ACkAAAABAAAAuHN0c3oAAAAAAAAAAAAAACkAAAvUAAAW0gAAAtkAAAEyAAAAuAAAAL8AAAJ6AAAA\n",
              "yAAAAKkAAAByAAABiAAAAMYAAABnAAAApAAAAqMAAAGKAAAA0wAAAKYAAALMAAABbgAAANIAAAD0\n",
              "AAADAQAAAW8AAADKAAAAzwAAAnwAAAFWAAAA2QAAAMAAAAJcAAABKwAAAJAAAACoAAABmgAAAM8A\n",
              "AAB0AAAAkQAAAKMAAAB0AAAAXgAAABRzdGNvAAAAAAAAAAEAAAAsAAAAYnVkdGEAAABabWV0YQAA\n",
              "AAAAAAAhaGRscgAAAAAAAAAAbWRpcmFwcGwAAAAAAAAAAAAAAAAtaWxzdAAAACWpdG9vAAAAHWRh\n",
              "dGEAAAABAAAAAExhdmY1Ny44My4xMDA=\n",
              "\">\n",
              "  Your browser does not support the video tag.\n",
              "</video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NyY60Gc9-IV1",
        "outputId": "e4687f70-81b3-4492-c13d-b9d140e3f518"
      },
      "source": [
        "print(param_v)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "        [[-2.7177e-02, -6.9709e-02, -1.0069e-01],\n",
            "         [ 3.8210e-02, -2.6388e-02, -1.2819e-01],\n",
            "         [ 2.3521e-01, -1.5309e-03, -9.2511e-02],\n",
            "         [-1.0704e-01, -7.9604e-02, -1.7047e-01]],\n",
            "\n",
            "        [[ 1.2869e-01, -1.2539e-01, -2.0540e-01],\n",
            "         [-4.0851e-02, -2.4771e-02, -5.2898e-02],\n",
            "         [ 1.6915e-01,  2.0242e-01, -5.7146e-02],\n",
            "         [-2.1052e-01, -9.1641e-02, -2.1956e-01]],\n",
            "\n",
            "        [[ 5.3117e-02, -6.1831e-02, -1.4591e-01],\n",
            "         [-7.0635e-02,  7.6858e-02, -1.2274e-01],\n",
            "         [ 3.8750e-02,  1.5665e-01, -1.4255e-01],\n",
            "         [-1.1924e-01, -4.5122e-03, -1.2790e-01]],\n",
            "\n",
            "        [[ 1.1208e-01, -8.2489e-02, -2.0415e-01],\n",
            "         [-6.0018e-02,  1.1944e-01, -1.2472e-01],\n",
            "         [ 6.8102e-02,  2.5328e-02, -1.8933e-01],\n",
            "         [-1.0932e-01, -5.7377e-02, -2.0915e-01]],\n",
            "\n",
            "        [[ 1.3940e-02, -1.6100e-02, -1.3430e-01],\n",
            "         [-4.1282e-02,  7.8360e-02, -1.1371e-01],\n",
            "         [ 1.1648e-01,  1.8326e-01, -1.3929e-01],\n",
            "         [-2.3162e-01, -1.3225e-02, -1.5177e-01]],\n",
            "\n",
            "        [[-8.6714e-03, -3.9670e-02, -1.7656e-01],\n",
            "         [-2.2724e-02,  4.7398e-02, -1.7211e-01],\n",
            "         [ 8.5110e-02,  1.5139e-01, -1.8146e-01],\n",
            "         [-2.0450e-01, -4.5531e-02, -2.5047e-01]],\n",
            "\n",
            "        [[ 9.0232e-02, -1.7286e-01, -2.5923e-01],\n",
            "         [-1.8177e-01,  7.8221e-02, -1.1430e-01],\n",
            "         [ 7.4378e-02,  1.7888e-01, -1.3612e-01],\n",
            "         [-1.7346e-01, -1.0262e-01, -2.2708e-01]],\n",
            "\n",
            "        [[ 2.2113e-02, -5.6231e-02, -2.0047e-01],\n",
            "         [-6.3918e-02,  1.2962e-01, -1.9197e-01],\n",
            "         [ 4.3140e-02,  1.7217e-01, -1.7681e-01],\n",
            "         [-1.2272e-01, -7.4532e-02, -2.0409e-01]],\n",
            "\n",
            "        [[ 1.3072e-02, -6.1375e-02, -1.9937e-01],\n",
            "         [ 1.5102e-03, -6.9213e-03, -2.3028e-01],\n",
            "         [-4.6100e-02,  8.8333e-02, -1.5316e-01],\n",
            "         [-3.2390e-02,  3.9518e-03, -1.3546e-01]],\n",
            "\n",
            "        [[-4.7203e-02,  2.9769e-02, -1.9570e-01],\n",
            "         [-8.3741e-02,  1.7588e-01, -1.5816e-01],\n",
            "         [ 5.5987e-02,  2.2117e-01, -1.8508e-01],\n",
            "         [-6.7025e-02, -2.0555e-02, -1.6853e-01]],\n",
            "\n",
            "        [[-4.9892e-02,  3.8024e-02, -1.4503e-01],\n",
            "         [ 3.5225e-02,  7.3526e-02, -2.0507e-01],\n",
            "         [ 1.1582e-01,  1.5539e-01, -1.7297e-01],\n",
            "         [-3.8287e-02, -1.7277e-03, -1.5603e-01]],\n",
            "\n",
            "        [[-5.4690e-02,  3.0774e-02, -2.1329e-01],\n",
            "         [ 2.9302e-02, -6.2520e-03, -1.9270e-01],\n",
            "         [ 9.6677e-02,  1.2975e-01, -1.7633e-01],\n",
            "         [-1.3589e-01, -5.6563e-02, -2.3527e-01]],\n",
            "\n",
            "        [[-5.4502e-02,  4.6079e-02, -2.0044e-01],\n",
            "         [-9.6371e-02, -8.4796e-03, -1.8027e-01],\n",
            "         [ 5.7486e-03,  1.2643e-01, -2.3120e-01],\n",
            "         [-9.6349e-02, -3.6795e-02, -2.2323e-01]],\n",
            "\n",
            "        [[-5.6058e-02,  5.5233e-02, -1.9825e-01],\n",
            "         [-2.2708e-02,  1.8688e-02, -2.5372e-01],\n",
            "         [ 6.1886e-02,  1.8013e-01, -1.9440e-01],\n",
            "         [-1.1058e-01,  3.5505e-03, -2.1094e-01]],\n",
            "\n",
            "        [[-4.2665e-02,  5.9884e-02, -1.8435e-01],\n",
            "         [ 4.8597e-03, -1.6438e-02, -2.5553e-01],\n",
            "         [-2.3645e-02,  1.3028e-01, -2.2181e-01],\n",
            "         [-5.4402e-02,  1.4986e-02, -2.0213e-01]],\n",
            "\n",
            "        [[-4.4498e-02,  5.1327e-02, -1.8126e-01],\n",
            "         [-1.9484e-02, -2.4478e-02, -2.1303e-01],\n",
            "         [-1.6255e-02,  4.3106e-02, -2.3639e-01],\n",
            "         [-4.9884e-02,  1.5861e-02, -2.0576e-01]],\n",
            "\n",
            "        [[-4.4737e-02,  4.6545e-02, -1.6935e-01],\n",
            "         [ 1.0351e-02,  2.0127e-03, -2.3282e-01],\n",
            "         [-1.5906e-02,  2.1927e-02, -1.7546e-01],\n",
            "         [-2.6867e-02, -7.4997e-03, -2.1220e-01]],\n",
            "\n",
            "        [[-2.7631e-02,  5.4981e-02, -1.5198e-01],\n",
            "         [ 1.3782e-02, -5.2455e-02, -2.0404e-01],\n",
            "         [ 3.3611e-02,  4.3256e-02, -1.2099e-01],\n",
            "         [-1.4488e-02,  5.2752e-03, -1.7867e-01]],\n",
            "\n",
            "        [[-1.8924e-02,  1.9112e-02, -1.4241e-01],\n",
            "         [ 1.5332e-03, -1.6863e-02, -1.9090e-01],\n",
            "         [ 4.0044e-03,  1.4289e-01, -2.3150e-01],\n",
            "         [ 1.0354e-02,  1.0214e-03, -1.7647e-01]],\n",
            "\n",
            "        [[ 5.3501e-03,  2.3770e-02, -1.2383e-01],\n",
            "         [ 2.1280e-02, -3.9768e-02, -1.6108e-01],\n",
            "         [-1.0711e-03,  9.1465e-02, -2.2525e-01],\n",
            "         [ 2.5458e-02,  1.7369e-03, -1.4309e-01]],\n",
            "\n",
            "        [[ 1.0442e-02,  7.5264e-03, -9.7143e-02],\n",
            "         [ 1.2624e-02, -7.7833e-02, -1.6575e-01],\n",
            "         [ 6.1658e-03,  1.1506e-02, -2.1710e-01],\n",
            "         [ 1.9754e-02,  9.1156e-04, -1.1929e-01]],\n",
            "\n",
            "        [[-1.6190e-03,  3.7910e-03, -6.3739e-02],\n",
            "         [ 1.5710e-03, -1.1210e-02, -1.5026e-01],\n",
            "         [ 1.9439e-02,  6.9435e-02, -1.6767e-01],\n",
            "         [ 6.9642e-03,  6.6464e-03, -6.9214e-02]],\n",
            "\n",
            "        [[ 1.0123e-03, -1.5783e-04, -1.9524e-02],\n",
            "         [ 6.7907e-03, -3.0947e-02, -1.0721e-01],\n",
            "         [-6.1991e-05, -1.5565e-02, -1.5499e-01],\n",
            "         [-9.9975e-03,  7.2841e-03, -3.2230e-02]],\n",
            "\n",
            "        [[ 7.9751e-04, -2.5461e-03,  1.4088e-02],\n",
            "         [-1.8403e-02,  1.1493e-02, -5.8452e-02],\n",
            "         [ 8.4954e-04, -6.0050e-03, -1.7780e-01],\n",
            "         [ 2.0971e-05,  7.0841e-03,  1.1745e-02]],\n",
            "\n",
            "        [[-9.6759e-04,  1.0436e-02,  6.5920e-03],\n",
            "         [ 1.6934e-03,  2.0238e-02,  1.0395e-02],\n",
            "         [ 8.5091e-03, -2.3055e-03, -5.4483e-02],\n",
            "         [ 5.3509e-05, -4.6799e-03, -7.2086e-03]],\n",
            "\n",
            "        [[ 2.1035e-04,  1.8592e-03,  4.8118e-03],\n",
            "         [ 6.6148e-03,  2.0575e-02,  2.0318e-02],\n",
            "         [ 1.4538e-02, -8.1312e-04,  3.5119e-03],\n",
            "         [-1.0482e-02,  1.0278e-02,  3.6359e-03]],\n",
            "\n",
            "        [[-1.1520e-04,  2.4660e-03, -1.5016e-02],\n",
            "         [ 2.6654e-03, -3.1825e-03,  1.9166e-04],\n",
            "         [ 2.2036e-03, -6.3178e-03, -2.4224e-03],\n",
            "         [ 1.1934e-03, -1.2712e-04, -3.1422e-03]],\n",
            "\n",
            "        [[-3.3338e-03,  7.6079e-03, -1.0976e-03],\n",
            "         [ 2.5794e-03, -3.9882e-03, -8.3028e-04],\n",
            "         [ 1.4761e-03, -8.1488e-05, -2.3026e-03],\n",
            "         [ 2.1296e-03,  4.2414e-05,  8.6821e-04]],\n",
            "\n",
            "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]], dtype=torch.float64,\n",
            "       requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSjNtAn0wdl9",
        "outputId": "577ea9a2-ef4e-4dea-9bce-3cff9a42bc0f"
      },
      "source": [
        "param_v.grad"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[  0.0000,   0.0000,   0.0000],\n",
              "         [  0.0000,   0.0000,   0.0000],\n",
              "         [  0.0000,   0.0000,   0.0000],\n",
              "         [  0.0000,   0.0000,   0.0000]],\n",
              "\n",
              "        [[-35.0000,  35.0000,  35.0000],\n",
              "         [ 35.0000,  35.0000,  35.0000],\n",
              "         [ 35.0000,  35.0000, -35.0000],\n",
              "         [ 30.2527,  35.0000, -35.0000]],\n",
              "\n",
              "        [[-35.0000,  35.0000,  35.0000],\n",
              "         [ 35.0000, -35.0000,  35.0000],\n",
              "         [ 35.0000, -35.0000, -35.0000],\n",
              "         [ 35.0000,  35.0000,  35.0000]],\n",
              "\n",
              "        [[-35.0000,  35.0000,  35.0000],\n",
              "         [ 35.0000, -35.0000,  35.0000],\n",
              "         [-35.0000,  35.0000, -35.0000],\n",
              "         [-35.0000,  35.0000, -35.0000]],\n",
              "\n",
              "        [[-35.0000,  35.0000,  35.0000],\n",
              "         [ 35.0000, -35.0000,  35.0000],\n",
              "         [ 35.0000,  35.0000, -35.0000],\n",
              "         [-35.0000,  35.0000,  35.0000]],\n",
              "\n",
              "        [[-35.0000,  35.0000,  35.0000],\n",
              "         [ 35.0000, -35.0000,  35.0000],\n",
              "         [ 35.0000,  35.0000,  35.0000],\n",
              "         [ -6.7152,  28.2333, -35.0000]],\n",
              "\n",
              "        [[-35.0000,  35.0000,  35.0000],\n",
              "         [ 35.0000, -35.0000,  35.0000],\n",
              "         [ 35.0000,  35.0000, -35.0000],\n",
              "         [  5.2146,  35.0000,  18.3369]],\n",
              "\n",
              "        [[-35.0000,  35.0000,  35.0000],\n",
              "         [ 35.0000, -35.0000,  35.0000],\n",
              "         [ 35.0000,  35.0000, -35.0000],\n",
              "         [ 35.0000,  35.0000,  35.0000]],\n",
              "\n",
              "        [[-35.0000,  35.0000,  35.0000],\n",
              "         [ 35.0000, -35.0000,  35.0000],\n",
              "         [ 35.0000,  35.0000,  35.0000],\n",
              "         [ 35.0000,  35.0000,  12.0546]],\n",
              "\n",
              "        [[-35.0000,  35.0000,  35.0000],\n",
              "         [ 35.0000, -35.0000,  35.0000],\n",
              "         [ 35.0000,  35.0000, -35.0000],\n",
              "         [ 13.8243,  35.0000,  35.0000]],\n",
              "\n",
              "        [[-35.0000,  35.0000,  35.0000],\n",
              "         [ 35.0000, -35.0000,  35.0000],\n",
              "         [ 35.0000,  35.0000, -35.0000],\n",
              "         [ 35.0000,  35.0000,  35.0000]],\n",
              "\n",
              "        [[-35.0000,  35.0000,  35.0000],\n",
              "         [ 35.0000, -35.0000,  35.0000],\n",
              "         [ 35.0000,  35.0000, -35.0000],\n",
              "         [ 35.0000,  35.0000,  35.0000]],\n",
              "\n",
              "        [[-35.0000,  35.0000,  35.0000],\n",
              "         [ 35.0000,  35.0000,  35.0000],\n",
              "         [ 35.0000,  35.0000, -35.0000],\n",
              "         [ 32.8776,  35.0000,  35.0000]],\n",
              "\n",
              "        [[-23.1367,  35.0000,  28.1229],\n",
              "         [ 35.0000,  35.0000, -35.0000],\n",
              "         [ 35.0000,  31.0084,  -6.2636],\n",
              "         [ 29.2635,  35.0000,  35.0000]],\n",
              "\n",
              "        [[ -8.4284, -12.1402, -17.8008],\n",
              "         [ 35.0000, -35.0000,  35.0000],\n",
              "         [ 30.6112,   1.3475,  30.4302],\n",
              "         [ -2.1469,  35.0000,  35.0000]],\n",
              "\n",
              "        [[ -8.5372,  21.3197, -11.8929],\n",
              "         [ 35.0000,  35.0000, -35.0000],\n",
              "         [ -3.3290,   3.5132,  35.0000],\n",
              "         [ -3.1150,  29.1600,   6.9302]],\n",
              "\n",
              "        [[-11.0819, -10.5890, -17.1984],\n",
              "         [ 35.0000,  35.0000, -35.0000],\n",
              "         [-18.1072, -17.6880,  35.0000],\n",
              "         [ -4.2068,  27.8930,  15.4048]],\n",
              "\n",
              "        [[-17.9439,   8.9038,  -7.7011],\n",
              "         [ 35.0000,  35.0000, -35.0000],\n",
              "         [ -7.7300,   9.0991,  27.7257],\n",
              "         [ -5.4953,  -5.6240,  -2.0048]],\n",
              "\n",
              "        [[-15.4948,   5.6168,  -8.5459],\n",
              "         [ 35.0000, -35.0000, -35.0000],\n",
              "         [  0.9936,   8.9698,  20.7666],\n",
              "         [ -5.3644,  13.1301,   1.7518]],\n",
              "\n",
              "        [[-13.2512,   5.0889,  -9.4666],\n",
              "         [ 35.0000, -35.0000, -35.0000],\n",
              "         [  8.3758,  11.2697,  19.8150],\n",
              "         [ 11.8288,   8.0788,  -3.3528]],\n",
              "\n",
              "        [[  4.5327,   3.8323,  -8.8555],\n",
              "         [  2.9912,   1.9936, -23.3250],\n",
              "         [ -6.5252,  11.1343,  20.5321],\n",
              "         [ 12.1725,   6.9033,  -4.8262]],\n",
              "\n",
              "        [[  5.4328,   5.3730,  -8.3191],\n",
              "         [ 28.8822,  17.0136, -21.5061],\n",
              "         [  5.5351,   8.4489,   2.8767],\n",
              "         [ 11.8796,   8.0985,  -4.8450]],\n",
              "\n",
              "        [[-11.6905,  -1.0134,  -8.4735],\n",
              "         [ 31.5871,   9.6144, -25.0218],\n",
              "         [  7.9665,  10.7132,   2.1084],\n",
              "         [ 11.0931,   9.7962,  -3.3421]],\n",
              "\n",
              "        [[  4.1315, -19.6350,  -5.3709],\n",
              "         [ 35.0000, -12.3607, -17.9773],\n",
              "         [ -7.5189,  -7.9191,   0.0553],\n",
              "         [ -6.9124,  10.3034,  -2.9337]],\n",
              "\n",
              "        [[  2.9726, -15.8988,  12.1987],\n",
              "         [-12.9500, -20.3635, -35.0000],\n",
              "         [  6.8775,  -8.9203,  -2.5131],\n",
              "         [  9.8121,  10.4123,  14.1655]],\n",
              "\n",
              "        [[-12.8308,   9.3559,  12.2144],\n",
              "         [-35.0000,  35.0000,  -9.5586],\n",
              "         [  9.2288,  -7.4076,  -1.7774],\n",
              "         [  9.4789,  -7.2548,  -4.6045]],\n",
              "\n",
              "        [[  6.0534,  14.8760,  11.4300],\n",
              "         [  9.3173,   5.7945,   5.5082],\n",
              "         [  7.4557,  -7.3328,  11.6269],\n",
              "         [ -8.0774,   9.6724,  11.5672]],\n",
              "\n",
              "        [[ -9.8648,  11.8779,  -7.2441],\n",
              "         [ 11.9679, -16.4298,   6.3556],\n",
              "         [  7.5409,  -7.9672,  -5.8728],\n",
              "         [  9.0323,  -8.0332,  -6.6142]],\n",
              "\n",
              "        [[ -9.1707,   9.5988,  -7.8804],\n",
              "         [  7.3807,  -6.7654,  -9.2461],\n",
              "         [  8.0991,  -8.1871,  -7.3970],\n",
              "         [  8.8226,   8.6458,   9.5250]],\n",
              "\n",
              "        [[  0.0000,   0.0000,   0.0000],\n",
              "         [  0.0000,   0.0000,   0.0000],\n",
              "         [  0.0000,   0.0000,   0.0000],\n",
              "         [  0.0000,   0.0000,   0.0000]]], dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AR8G8ZZBF3FL"
      },
      "source": [
        "ani.save('diffdrape.mp4')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmxdJAtmvkAW"
      },
      "source": [
        "torch.save(param_v, 'trajectory.pt')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}